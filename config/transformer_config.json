{
    "model": {
        "vocab_size": 32000,
        "hidden_size": 768,
        "num_heads": 12,
        "num_layers": 12,
        "head_dim": 64,
        "intermediate_size": 3072,
        "max_seq_length": 32
    },
    "training": {
        "batch_size": 64,
        "num_epochs": 6,
        "dropout_rate": 0.1,
        "weight_decay": 0.01
    },
    "attention": {
        "use_flash_attention": true,
        "use_rope": true,
        "use_sliding_window": true,
        "window_size": 256,
        "use_gqa": true,
        "num_kv_heads": 4
    },
    "optimization": {
        "use_fp16": true,
        "use_gradient_checkpointing": true,
        "memory_pool_size": 1024
    },
    "paths": {
        "save_directory": "models",
        "model_name": "transformer_new_corpus",
        "checkpoint_frequency": 2
    },
    "beam_search": {
        "beam_size": 5,
        "length_penalty": 0.6,
        "temperature": 1.0,
        "top_p": 0.9,
        "max_length": 20
    },
    "load_from_checkpoint": false,
    "checkpoint_to_load": ""
} 