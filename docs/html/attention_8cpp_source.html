<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Transformer CPP: src/attention.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Transformer CPP
   </div>
   <div id="projectbrief">A C++/CUDA implementation of a Transformer model</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function() { init_codefold(0); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle"><div class="title">attention.cpp</div></div>
</div><!--header-->
<div class="contents">
<a href="attention_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="preprocessor">#include &quot;../include/attention.hpp&quot;</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="preprocessor">#include &quot;../include/cuda/cuda_utils.cuh&quot;</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="preprocessor">#include &quot;../include/gqa.hpp&quot;</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="preprocessor">#include &quot;../include/performance_metrics.hpp&quot;</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="preprocessor">#include &quot;../include/transformer.hpp&quot;</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="preprocessor">#include &quot;../include/config.hpp&quot;</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="preprocessor">#include &quot;<a class="code" href="attention_8hpp.html">attention.hpp</a>&quot;</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="preprocessor">#include &lt;algorithm&gt;</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="preprocessor">#include &lt;cmath&gt;</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="preprocessor">#include &lt;string&gt;</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="preprocessor">#include &quot;../include/half_precision.hpp&quot;</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span> </div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="keyword">extern</span> <a class="code hl_class" href="classPerformanceMetrics.html">PerformanceMetrics</a> <a class="code hl_variable" href="attention_8cpp.html#a420192cf7ad6664706c6e334d57142ff">metrics</a>;</div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span> </div>
<div class="foldopen" id="foldopen00016" data-start="{" data-end="}">
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#a15a9a52d7adb5b6c4fe5cddb273acff6">   16</a></span><a class="code hl_class" href="classVector.html">Vector</a> <a class="code hl_function" href="classMultiHeadAttention.html#a15a9a52d7adb5b6c4fe5cddb273acff6">MultiHeadAttention::apply_rope</a>(<span class="keyword">const</span> <a class="code hl_class" href="classVector.html">Vector</a>&amp; x, <span class="keywordtype">size_t</span> position)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span>    <a class="code hl_class" href="classVector.html">Vector</a> result = x;</div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span>    <span class="comment">// Apply rotary position embeddings</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; x.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); i += 2) {</div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span>        <span class="keywordflow">if</span> (i + 1 &gt;= x.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>()) {</div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span>            std::cout &lt;&lt; <span class="stringliteral">&quot;Breaking at i=&quot;</span> &lt;&lt; i &lt;&lt; <span class="stringliteral">&quot; (odd size)&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span>            <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span>        }</div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span> </div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span>        <span class="keywordtype">float</span> x_i = x[i];</div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span>        <span class="keywordtype">float</span> x_i1 = x[i + 1];</div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span> </div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span>        <span class="comment">// Each pair of elements belongs to a specific head and position within that head</span></div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span>        <span class="keywordtype">size_t</span> pair_idx = i / 2; <span class="comment">// Index of the current pair</span></div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span>        <span class="keywordtype">size_t</span> head_idx =</div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span>            pair_idx / (<a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> / 2); <span class="comment">// Which head (using half head_dim since we process pairs)</span></div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span>        <span class="keywordtype">size_t</span> dim_idx = pair_idx % (<a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> / 2); <span class="comment">// Position within head (using half head_dim)</span></div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span>        <span class="keywordtype">size_t</span> cache_idx = head_idx * <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> + dim_idx; <span class="comment">// Correct: direct mapping to cache</span></div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span> </div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span>        <span class="keywordflow">try</span> {</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span>            <span class="keywordtype">float</span> cos_theta = <a class="code hl_function" href="classMultiHeadAttention.html#a02d15d5c760c9461189debefe54dab99">get_cos_cached</a>(position, cache_idx);</div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span>            <span class="keywordtype">float</span> sin_theta = <a class="code hl_function" href="classMultiHeadAttention.html#ad02e8c0946a244a380de6a145afbce7b">get_sin_cached</a>(position, cache_idx);</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span> </div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span>            result[i] = x_i * cos_theta - x_i1 * sin_theta;</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span>            result[i + 1] = x_i * sin_theta + x_i1 * cos_theta;</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>        } <span class="keywordflow">catch</span> (<span class="keyword">const</span> std::exception&amp; e) {</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span>            std::cout &lt;&lt; <span class="stringliteral">&quot;Error in RoPE application:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span>            std::cout &lt;&lt; <span class="stringliteral">&quot;- Error message: &quot;</span> &lt;&lt; e.what() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>            std::cout &lt;&lt; <span class="stringliteral">&quot;- Current indices: pos=&quot;</span> &lt;&lt; position &lt;&lt; <span class="stringliteral">&quot;, cache_idx=&quot;</span> &lt;&lt; cache_idx</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>                      &lt;&lt; <span class="stringliteral">&quot;, i=&quot;</span> &lt;&lt; i &lt;&lt; std::endl;</div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>            <span class="keywordflow">throw</span>;</div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span>        }</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>    }</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span> </div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>}</div>
</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span> </div>
<div class="foldopen" id="foldopen00053" data-start="{" data-end="}">
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#a2ae83b92dbfb2da91f2a158d17c701ff">   53</a></span><a class="code hl_class" href="classMatrix.html">Matrix</a> <a class="code hl_function" href="classMultiHeadAttention.html#a2ae83b92dbfb2da91f2a158d17c701ff">MultiHeadAttention::flash_attention</a>(<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; Q, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; K, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; V,</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>                                           <span class="keyword">const</span> <a class="code hl_class" href="classAttentionMask.html">AttentionMask</a>&amp; mask)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\n=== MultiHeadAttention::flash_attention START ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>    <span class="keyword">const</span> <span class="keywordtype">size_t</span> seq_len = Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>();</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>    <span class="keyword">const</span> <span class="keywordtype">size_t</span> <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> = Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>();</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span> </div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>    <span class="comment">// Block sizes based on hardware cache sizes</span></div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span>    <span class="keyword">const</span> <span class="keywordtype">size_t</span> Br = std::min(<span class="keywordtype">size_t</span>(256), seq_len); <span class="comment">// Q block size</span></div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>    <span class="keyword">const</span> <span class="keywordtype">size_t</span> Bc = std::min(<span class="keywordtype">size_t</span>(256), seq_len); <span class="comment">// K/V block size</span></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span> </div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> O(seq_len, <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>, 0.0f);</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>    std::vector&lt;float&gt; L(seq_len, 0.0f);                                    <span class="comment">// Scale factors</span></div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>    std::vector&lt;float&gt; m(seq_len, -std::numeric_limits&lt;float&gt;::infinity()); <span class="comment">// Max values</span></div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span> </div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>    <span class="comment">// Iterate over blocks</span></div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> kr = 0; kr &lt; seq_len; kr += Br) {</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>        <span class="keywordtype">size_t</span> kr_end = std::min(kr + Br, seq_len);</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span> </div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> kc = 0; kc &lt; seq_len; kc += Bc) {</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>            <span class="keywordtype">size_t</span> kc_end = std::min(kc + Bc, seq_len);</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span> </div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>            <span class="comment">// Load Q, K, V blocks</span></div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>            <a class="code hl_class" href="classMatrix.html">Matrix</a> Qb = Q.<a class="code hl_function" href="classMatrix.html#a864bfe1ae2f2a1eb34453bb8206c695f">block</a>(kr, 0, kr_end - kr, <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>);</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>            <a class="code hl_class" href="classMatrix.html">Matrix</a> Kb = K.<a class="code hl_function" href="classMatrix.html#a864bfe1ae2f2a1eb34453bb8206c695f">block</a>(kc, 0, kc_end - kc, <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>);</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>            <a class="code hl_class" href="classMatrix.html">Matrix</a> Vb = V.<a class="code hl_function" href="classMatrix.html#a864bfe1ae2f2a1eb34453bb8206c695f">block</a>(kc, 0, kc_end - kc, <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>);</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span> </div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>            <span class="comment">// Compute attention scores for this block</span></div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span>            <a class="code hl_class" href="classMatrix.html">Matrix</a> S = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(Qb, Kb.<a class="code hl_function" href="classMatrix.html#a759661b75b9681f3a89ff75e27933b3a">transpose</a>());</div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>            S *= 1.0f / std::sqrt(<span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(<a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>));</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span> </div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>            <span class="comment">// Apply mask if needed</span></div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>            <span class="keywordflow">if</span> (!mask.<a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>.<a class="code hl_function" href="classMatrix.html#a6efb67c1b998ea7ffdc0a1e1b4252e62">empty</a>()) {</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = kr; i &lt; kr_end; i++) {</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = kc; j &lt; kc_end; j++) {</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>                        <span class="keywordflow">if</span> (mask.<a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>(i, j) == 0.0f) {</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>                            S(i - kr, j - kc) = -std::numeric_limits&lt;float&gt;::infinity();</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>                        }</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>                    }</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>                }</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>            }</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span> </div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>            <span class="comment">// Update running max and scale factors</span></div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; S.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(); i++) {</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>                <span class="keywordtype">float</span> mi = m[i + kr];</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>                <span class="keywordtype">float</span> li = L[i + kr];</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span> </div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; S.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>                    <span class="keywordtype">float</span> sij = S(i, j);</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>                    <span class="keywordflow">if</span> (sij &gt; mi) {</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>                        <span class="keywordtype">float</span> mi_new = sij;</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>                        <span class="keywordtype">float</span> scale = std::exp(mi - mi_new);</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>                        li *= scale;</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>                        mi = mi_new;</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span> </div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>                        <span class="comment">// Scale existing output</span></div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>                        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>; d++) {</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>                            O(i + kr, d) *= scale;</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>                        }</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>                    }</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span> </div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>                    <span class="keywordtype">float</span> pij = std::exp(sij - mi);</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>                    li += pij;</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span> </div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>                    <span class="comment">// Update output</span></div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>; d++) {</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>                        O(i + kr, d) += pij * Vb(j, d);</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>                    }</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>                }</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span> </div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>                m[i + kr] = mi;</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>                L[i + kr] = li;</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>            }</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>        }</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>    }</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span> </div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>    <span class="comment">// Normalize output</span></div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; seq_len; i++) {</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>; d++) {</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>            O(i, d) /= L[i];</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>        }</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>    }</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span> </div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;=== MultiHeadAttention::flash_attention END ===\n&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>    <span class="keywordflow">return</span> O;</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>}</div>
</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span> </div>
<div class="foldopen" id="foldopen00139" data-start="{" data-end="}">
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#a9c5b1b6ba053f3891ddde42588fb8e7e">  139</a></span><a class="code hl_class" href="classMatrix.html">Matrix</a> <a class="code hl_function" href="classMultiHeadAttention.html#a9c5b1b6ba053f3891ddde42588fb8e7e">MultiHeadAttention::forward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; x, <span class="keyword">const</span> <a class="code hl_class" href="classAttentionMask.html">AttentionMask</a>&amp; mask,</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>                                   <span class="keyword">const</span> std::optional&lt;KVCache&gt;&amp; kv_cache) {</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>    <a class="code hl_variable" href="attention_8cpp.html#a420192cf7ad6664706c6e334d57142ff">metrics</a>.<a class="code hl_function" href="classPerformanceMetrics.html#aab6bfb13b95e4b95ff6b1aa0e0ba50e3">start_timer</a>(<span class="stringliteral">&quot;attention_computation&quot;</span>);</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span> </div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>    <span class="comment">// Get use_fp16 from member variable instead of global config</span></div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>    <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">bool</span> use_fp16 = <a class="code hl_variable" href="classMultiHeadAttention.html#a4314826233aeaa0ba472897dbb1ee7e9">use_fp16_</a>;</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>    </div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>    <span class="comment">// Convert input to FP16 if needed</span></div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> input_matrix = x;</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>    <span class="keywordflow">if</span> (use_fp16) {</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>        <a class="code hl_function" href="classHalfPrecisionTraining.html#a82deaaee41c1b5d49adf8049b9a0d2e3">HalfPrecisionTraining::convert_to_fp16</a>(input_matrix);</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>    }</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span> </div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Checking GQA configuration:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- use_gqa: &quot;</span> &lt;&lt; (<a class="code hl_variable" href="classMultiHeadAttention.html#a58478592fe138677a9a9b923460dfaef">use_gqa</a> ? <span class="stringliteral">&quot;true&quot;</span> : <span class="stringliteral">&quot;false&quot;</span>) &lt;&lt; std::endl;</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- num_heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- num_kv_heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a5b61a3ff6c0d3debbf2c73e3a110aecc">num_kv_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span> </div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>    <span class="comment">// Use GQA if enabled</span></div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classMultiHeadAttention.html#a58478592fe138677a9a9b923460dfaef">use_gqa</a> &amp;&amp; <a class="code hl_variable" href="classMultiHeadAttention.html#a5b61a3ff6c0d3debbf2c73e3a110aecc">num_kv_heads</a> != <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>) {</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;About to call GroupedQueryAttention::forward&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>        <a class="code hl_class" href="classGroupedQueryAttention.html">GroupedQueryAttention</a> gqa(<a class="code hl_variable" href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">hidden_size</a>, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, <a class="code hl_variable" href="classMultiHeadAttention.html#a5b61a3ff6c0d3debbf2c73e3a110aecc">num_kv_heads</a>, <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>, <a class="code hl_variable" href="classMultiHeadAttention.html#ad4b2bd9329b13739e3070253fa707abb">dropout_prob</a>);</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>        </div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>        <span class="comment">// Convert back to FP32 before GQA if using FP16</span></div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>        <span class="keywordflow">if</span> (use_fp16) {</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>            <a class="code hl_function" href="classHalfPrecisionTraining.html#aa968c90058884f141bdc068b6ff64b9b">HalfPrecisionTraining::convert_to_fp32</a>(input_matrix);</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>        }</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>        </div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> gqa_output = gqa.<a class="code hl_function" href="classGroupedQueryAttention.html#ad84a75705d197a794de0d3971e656a45">forward</a>(input_matrix, mask, kv_cache);</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>        </div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>        <span class="comment">// Convert GQA output to FP16 if needed</span></div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>        <span class="keywordflow">if</span> (use_fp16) {</div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>            <a class="code hl_function" href="classHalfPrecisionTraining.html#a82deaaee41c1b5d49adf8049b9a0d2e3">HalfPrecisionTraining::convert_to_fp16</a>(gqa_output);</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>        }</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>        </div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>        <span class="keywordflow">return</span> gqa_output;</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>    }</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span> </div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>    <span class="comment">// Regular attention implementation continues...</span></div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;=== MultiHeadAttention::forward START ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Input shape: &quot;</span> &lt;&lt; x.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; x.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span> </div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>    <span class="comment">// Calculate true batch size and sequence length</span></div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>    <span class="keyword">const</span> <span class="keywordtype">size_t</span> seq_len = mask.<a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>();      <span class="comment">// Get sequence length from mask</span></div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>    <span class="keyword">const</span> <span class="keywordtype">size_t</span> batch_size = x.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() / seq_len; <span class="comment">// Correct: batch_size = total_rows / seq_len</span></div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span> </div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Calculated dimensions:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- batch_size: &quot;</span> &lt;&lt; batch_size &lt;&lt; std::endl;</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- seq_len: &quot;</span> &lt;&lt; seq_len &lt;&lt; std::endl;</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- num_heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- head_dim: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span> </div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span><span class="comment">// Project input to Q, K, V</span></div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span><span class="preprocessor">#ifdef CUDA_AVAILABLE</span></div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\n=== CUDA EXECUTION PATH ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;CUDA is available and will be used for matrix operations&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>    <span class="comment">// Move matrices to GPU</span></div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Moving matrices to GPU...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> Q, K, V;</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>    <span class="keywordflow">try</span> {</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> x_gpu = input_matrix.to_gpu();</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;x moved to GPU successfully&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> query_proj_gpu = <a class="code hl_variable" href="classMultiHeadAttention.html#a18362671ef7860ee292602e8a80fdfe3">query_proj</a>.to_gpu();</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;query_proj moved to GPU successfully&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> key_proj_gpu = <a class="code hl_variable" href="classMultiHeadAttention.html#adccbc1658f1f13e00ea1a7cb71ec9030">key_proj</a>.to_gpu();</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;key_proj moved to GPU successfully&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> value_proj_gpu = <a class="code hl_variable" href="classMultiHeadAttention.html#aad0999daf1477b120755a3413685812b">value_proj</a>.to_gpu();</div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;value_proj moved to GPU successfully&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span> </div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>        <span class="comment">// Project input using CUDA</span></div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Performing CUDA matrix multiplications...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>        Q = cuda_matmul(x_gpu, query_proj_gpu);</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Q computation successful&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>        K = cuda_matmul(x_gpu, key_proj_gpu);</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;K computation successful&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>        V = cuda_matmul(x_gpu, value_proj_gpu);</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;V computation successful&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;=== CUDA operations completed successfully ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>    } <span class="keywordflow">catch</span> (<span class="keyword">const</span> std::runtime_error&amp; e) {</div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;\n=== CUDA EXECUTION FAILED - Falling back to CPU ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>        std::cerr &lt;&lt; <span class="stringliteral">&quot;CUDA error: &quot;</span> &lt;&lt; e.what() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>        std::cerr &lt;&lt; <span class="stringliteral">&quot;Falling back to CPU implementation&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>        <span class="comment">// Fall back to CPU implementation</span></div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>        Q = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(input_matrix, <a class="code hl_variable" href="classMultiHeadAttention.html#a18362671ef7860ee292602e8a80fdfe3">query_proj</a>);</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>        K = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(input_matrix, <a class="code hl_variable" href="classMultiHeadAttention.html#adccbc1658f1f13e00ea1a7cb71ec9030">key_proj</a>);</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>        V = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(input_matrix, <a class="code hl_variable" href="classMultiHeadAttention.html#aad0999daf1477b120755a3413685812b">value_proj</a>);</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>    }</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>    <span class="comment">// CPU fallback</span></div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>    Q = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(input_matrix, <a class="code hl_variable" href="classMultiHeadAttention.html#a18362671ef7860ee292602e8a80fdfe3">query_proj</a>);</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>    K = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(input_matrix, <a class="code hl_variable" href="classMultiHeadAttention.html#adccbc1658f1f13e00ea1a7cb71ec9030">key_proj</a>);</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>    V = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(input_matrix, <a class="code hl_variable" href="classMultiHeadAttention.html#aad0999daf1477b120755a3413685812b">value_proj</a>);</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span> </div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>    <span class="comment">// Convert Q,K,V to FP16 if needed</span></div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>    <span class="keywordflow">if</span> (use_fp16) {</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>        <a class="code hl_function" href="classHalfPrecisionTraining.html#a82deaaee41c1b5d49adf8049b9a0d2e3">HalfPrecisionTraining::convert_to_fp16</a>(Q);</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>        <a class="code hl_function" href="classHalfPrecisionTraining.html#a82deaaee41c1b5d49adf8049b9a0d2e3">HalfPrecisionTraining::convert_to_fp16</a>(K);</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>        <a class="code hl_function" href="classHalfPrecisionTraining.html#a82deaaee41c1b5d49adf8049b9a0d2e3">HalfPrecisionTraining::convert_to_fp16</a>(V);</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>    }</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span> </div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>    <span class="comment">// Handle KV cache if present</span></div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>    <span class="keywordflow">if</span> (kv_cache) {</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>        <span class="comment">// Concatenate current K/V with cached K/V</span></div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> new_K(K.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() + kv_cache-&gt;key_cache.rows(), K.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>());</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> new_V(V.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() + kv_cache-&gt;value_cache.rows(), V.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>());</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span> </div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>        <span class="comment">// Copy cached values first</span></div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; kv_cache-&gt;key_cache.rows(); i++) {</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; K.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>                new_K(i, j) = kv_cache-&gt;key_cache.<a class="code hl_function" href="classMatrix.html#a7a12d2cbbf595077f94c5e73bc6bc04a">at</a>(i, j);</div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span>                new_V(i, j) = kv_cache-&gt;value_cache.<a class="code hl_function" href="classMatrix.html#a7a12d2cbbf595077f94c5e73bc6bc04a">at</a>(i, j);</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>            }</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>        }</div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span> </div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>        <span class="comment">// Copy new values</span></div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; K.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(); i++) {</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; K.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>                new_K(i + kv_cache-&gt;key_cache.rows(), j) = K(i, j);</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span>                new_V(i + kv_cache-&gt;value_cache.rows(), j) = V(i, j);</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>            }</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>        }</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span> </div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>        <span class="comment">// Log cache usage</span></div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Using KV cache:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- Cached K shape: &quot;</span> &lt;&lt; kv_cache-&gt;key_cache.rows() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span></div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span>                  &lt;&lt; kv_cache-&gt;key_cache.cols() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- Cached V shape: &quot;</span> &lt;&lt; kv_cache-&gt;value_cache.rows() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span></div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span>                  &lt;&lt; kv_cache-&gt;value_cache.cols() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- New K shape: &quot;</span> &lt;&lt; new_K.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; new_K.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- New V shape: &quot;</span> &lt;&lt; new_V.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; new_V.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span> </div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span>        K = std::move(new_K);</div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>        V = std::move(new_V);</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span>    }</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span> </div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>    <span class="comment">// Apply RoPE to Q and K if enabled</span></div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classMultiHeadAttention.html#a6eaf4f61461419d9b2273d8ea5b61c8c">use_rope</a>) {</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>        <span class="comment">// Check dimensions before applying RoPE</span></div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span>        <span class="keywordflow">if</span> (Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() % 2 != 0) {</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>            <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;RoPE requires even dimension size, got: &quot;</span> +</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span>                                     std::to_string(Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>()));</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>        }</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span> </div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>        <span class="comment">// Apply RoPE to each position in the sequence</span></div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> pos = 0; pos &lt; seq_len; pos++) {</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> b = 0; b &lt; batch_size; b++) {</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>                <span class="keywordtype">size_t</span> idx = b * seq_len + pos;</div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span>                <span class="comment">// Bounds check</span></div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>                <span class="keywordflow">if</span> (idx &gt;= Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>()) {</div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>                    <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;RoPE index out of bounds: &quot;</span> + std::to_string(idx) +</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>                                             <span class="stringliteral">&quot; &gt;= &quot;</span> + std::to_string(Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>()));</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span>                }</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span> </div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>                <span class="comment">// Get row vectors for Q and K</span></div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>                <a class="code hl_class" href="classVector.html">Vector</a> q_row(Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>());</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span>                <a class="code hl_class" href="classVector.html">Vector</a> k_row(K.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>());</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>                    q_row[j] = Q(idx, j);</div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>                    k_row[j] = K(idx, j);</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>                }</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span> </div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>                <span class="comment">// Apply RoPE</span></div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>                <a class="code hl_class" href="classVector.html">Vector</a> q_rotated = <a class="code hl_function" href="classMultiHeadAttention.html#a15a9a52d7adb5b6c4fe5cddb273acff6">apply_rope</a>(q_row, pos);</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>                <a class="code hl_class" href="classVector.html">Vector</a> k_rotated = <a class="code hl_function" href="classMultiHeadAttention.html#a15a9a52d7adb5b6c4fe5cddb273acff6">apply_rope</a>(k_row, pos);</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span> </div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>                <span class="comment">// Update matrices with rotated vectors</span></div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>                    Q(idx, j) = q_rotated[j];</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>                    K(idx, j) = k_rotated[j];</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>                }</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>            }</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>        }</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>    }</div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span> </div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Q shape: &quot;</span> &lt;&lt; Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;K shape: &quot;</span> &lt;&lt; K.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; K.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;V shape: &quot;</span> &lt;&lt; V.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; V.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span> </div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span>    <span class="comment">// Add debug output to verify flag</span></div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Using flash attention: &quot;</span> &lt;&lt; (this-&gt;<a class="code hl_variable" href="classMultiHeadAttention.html#a49435188dcf74478d543f7f4124bd25d">use_flash</a> ? <span class="stringliteral">&quot;true&quot;</span> : <span class="stringliteral">&quot;false&quot;</span>) &lt;&lt; std::endl;</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span> </div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> attention_output;</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>    <span class="keywordflow">if</span> (this-&gt;<a class="code hl_variable" href="classMultiHeadAttention.html#a49435188dcf74478d543f7f4124bd25d">use_flash</a> &amp;&amp; !kv_cache) {</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>        attention_output = <a class="code hl_function" href="classMultiHeadAttention.html#a2ae83b92dbfb2da91f2a158d17c701ff">flash_attention</a>(Q, K, V, mask);</div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span>        attention_output = <a class="code hl_function" href="classMultiHeadAttention.html#aa63f2eb55c928afcbaabe2bed9b5fe9f">standard_attention</a>(Q, K, V, mask);</div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span>    }</div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span> </div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>    <span class="comment">// Convert back to FP32 for output projection</span></div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span>    <span class="keywordflow">if</span> (use_fp16) {</div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span>        <a class="code hl_function" href="classHalfPrecisionTraining.html#aa968c90058884f141bdc068b6ff64b9b">HalfPrecisionTraining::convert_to_fp32</a>(attention_output);</div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span>    }</div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span> </div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Attention output before projection shape: &quot;</span> &lt;&lt; attention_output.rows() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span></div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span>              &lt;&lt; attention_output.cols() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span> </div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span>    <span class="comment">// Project output</span></div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> output = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(attention_output, <a class="code hl_variable" href="classMultiHeadAttention.html#a4a1b86106c4351af679f4e0e2a8a0811">output_proj</a>);</div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Final output shape: &quot;</span> &lt;&lt; output.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; output.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;=== MultiHeadAttention::forward END ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span> </div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span>    <span class="keywordflow">try</span> {</div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Recording attention metrics:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- seq_len: &quot;</span> &lt;&lt; seq_len &lt;&lt; std::endl;</div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- num_heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- head_dim: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Recording FLOPS...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span>        <a class="code hl_variable" href="attention_8cpp.html#a420192cf7ad6664706c6e334d57142ff">metrics</a>.<a class="code hl_function" href="classPerformanceMetrics.html#ae1c4afd36fc5c55685cd183fa80c1125">record_attention_flops</a>(seq_len, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>);</div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Stopping timer...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span>        <a class="code hl_variable" href="attention_8cpp.html#a420192cf7ad6664706c6e334d57142ff">metrics</a>.<a class="code hl_function" href="classPerformanceMetrics.html#a906fa724ba88cb06250ef1624f494114">stop_timer</a>(<span class="stringliteral">&quot;attention_computation&quot;</span>);</div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Successfully recorded metrics&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span> </div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Moving output matrix...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>        <span class="keywordflow">return</span> std::move(output); <span class="comment">// Explicit move</span></div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>    } <span class="keywordflow">catch</span> (<span class="keyword">const</span> std::exception&amp; e) {</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Error after forward pass:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- Error message: &quot;</span> &lt;&lt; e.what() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- seq_len: &quot;</span> &lt;&lt; seq_len &lt;&lt; std::endl;</div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- num_heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- head_dim: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>        <span class="keywordflow">throw</span>;</div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span>    }</div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span>}</div>
</div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span> </div>
<div class="foldopen" id="foldopen00364" data-start="{" data-end="}">
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#a0386f6537c985151921e37a2008d6d59">  364</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classMultiHeadAttention.html#a0386f6537c985151921e37a2008d6d59">MultiHeadAttention::save</a>(std::ostream&amp; os)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\n=== MultiHeadAttention::save START ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span> </div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>    <span class="comment">// Save dimensions and configuration</span></div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Saving configuration...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Number of heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Head dimension: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>    os.write(<span class="keyword">reinterpret_cast&lt;</span><span class="keyword">const </span><span class="keywordtype">char</span>*<span class="keyword">&gt;</span>(&amp;<a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>), <span class="keyword">sizeof</span>(<a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>));</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span>    os.write(<span class="keyword">reinterpret_cast&lt;</span><span class="keyword">const </span><span class="keywordtype">char</span>*<span class="keyword">&gt;</span>(&amp;<a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>), <span class="keyword">sizeof</span>(<a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>));</div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span> </div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span>    <span class="comment">// Save projection matrices</span></div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\nSaving projection matrices...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Query projection shape: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a18362671ef7860ee292602e8a80fdfe3">query_proj</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a18362671ef7860ee292602e8a80fdfe3">query_proj</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>()</div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span>              &lt;&lt; std::endl;</div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#a18362671ef7860ee292602e8a80fdfe3">query_proj</a>.<a class="code hl_function" href="classMatrix.html#aefe021b305effc8062930719bcd532ef">save</a>(os);</div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Key projection shape: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#adccbc1658f1f13e00ea1a7cb71ec9030">key_proj</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#adccbc1658f1f13e00ea1a7cb71ec9030">key_proj</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#adccbc1658f1f13e00ea1a7cb71ec9030">key_proj</a>.<a class="code hl_function" href="classMatrix.html#aefe021b305effc8062930719bcd532ef">save</a>(os);</div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Value projection shape: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#aad0999daf1477b120755a3413685812b">value_proj</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#aad0999daf1477b120755a3413685812b">value_proj</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>()</div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span>              &lt;&lt; std::endl;</div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#aad0999daf1477b120755a3413685812b">value_proj</a>.<a class="code hl_function" href="classMatrix.html#aefe021b305effc8062930719bcd532ef">save</a>(os);</div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Output projection shape: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a4a1b86106c4351af679f4e0e2a8a0811">output_proj</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a4a1b86106c4351af679f4e0e2a8a0811">output_proj</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>()</div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span>              &lt;&lt; std::endl;</div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#a4a1b86106c4351af679f4e0e2a8a0811">output_proj</a>.<a class="code hl_function" href="classMatrix.html#aefe021b305effc8062930719bcd532ef">save</a>(os);</div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span> </div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;=== MultiHeadAttention::save END ===\n&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>}</div>
</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span> </div>
<div class="foldopen" id="foldopen00391" data-start="{" data-end="}">
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#acdb722e2273e30fee53d5dc11d60e956">  391</a></span>std::unique_ptr&lt;MultiHeadAttention&gt; <a class="code hl_function" href="classMultiHeadAttention.html#acdb722e2273e30fee53d5dc11d60e956">MultiHeadAttention::load</a>(std::istream&amp; is, <span class="keyword">const</span> <a class="code hl_class" href="classTransformerConfig.html">TransformerConfig</a>&amp; config) {</div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\n=== MultiHeadAttention::load START ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span> </div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span>    <span class="comment">// Read configuration</span></div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Reading configuration...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span>    <span class="keywordtype">size_t</span> <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>;</div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>    is.read(<span class="keyword">reinterpret_cast&lt;</span><span class="keywordtype">char</span>*<span class="keyword">&gt;</span>(&amp;<a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>), <span class="keyword">sizeof</span>(<a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>));</div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>    is.read(<span class="keyword">reinterpret_cast&lt;</span><span class="keywordtype">char</span>*<span class="keyword">&gt;</span>(&amp;<a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>), <span class="keyword">sizeof</span>(<a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>));</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Number of heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Head dimension: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span> </div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>    <span class="keywordtype">size_t</span> <a class="code hl_variable" href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">hidden_size</a> = <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> * <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>;</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span> </div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span>    <span class="comment">// Create attention instance with config parameters</span></div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span>    <span class="keyword">auto</span> attention = std::make_unique&lt;MultiHeadAttention&gt;(</div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">hidden_size</a>, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>, config.<a class="code hl_variable" href="classTransformerConfig.html#a2475d19613be8a719cf766e3bd09e583">dropout_rate</a>, </div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span>        config.<a class="code hl_variable" href="classTransformerConfig.html#aeef975a7d6166599e846df0ad66e8a6b">use_flash_attention</a>, config.<a class="code hl_variable" href="classTransformerConfig.html#a6991bb420dcaf858cc30dea8211d27fb">use_rope</a>, </div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span>        config.<a class="code hl_variable" href="classTransformerConfig.html#a067567832bcaacd2aad3e10862ca0846">use_sliding_window</a>, config.<a class="code hl_variable" href="classTransformerConfig.html#a9ee7210af942fef7cea9812b509b4f01">window_size</a>, </div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span>        config.<a class="code hl_variable" href="classTransformerConfig.html#a5509ab5f50885f2cf531df9d4dd85e0d">use_gqa</a>, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, config.<a class="code hl_variable" href="classTransformerConfig.html#a0b988766f47cdbac7f2564d6d464092d">max_seq_length</a>, config.<a class="code hl_variable" href="classTransformerConfig.html#af9260917b6dcbc2ed87690ac8ce6e9fe">use_fp16</a>);</div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span> </div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span>    <span class="comment">// Load projection matrices</span></div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\nLoading projection matrices...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>    attention-&gt;query_proj = <a class="code hl_function" href="classMatrix.html#ac5cf026a1e0349e348c67f285271d417">Matrix::load</a>(is);</div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>    attention-&gt;key_proj = <a class="code hl_function" href="classMatrix.html#ac5cf026a1e0349e348c67f285271d417">Matrix::load</a>(is);</div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span>    attention-&gt;value_proj = <a class="code hl_function" href="classMatrix.html#ac5cf026a1e0349e348c67f285271d417">Matrix::load</a>(is);</div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>    attention-&gt;output_proj = <a class="code hl_function" href="classMatrix.html#ac5cf026a1e0349e348c67f285271d417">Matrix::load</a>(is);</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span> </div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span>    <span class="comment">// Validate loaded matrices</span></div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\nValidating loaded matrices...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>    <span class="keyword">auto</span> validate_matrix = [](<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; m, <span class="keyword">const</span> std::string&amp; name) {</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>        <span class="keywordflow">if</span> (m.<a class="code hl_function" href="classMatrix.html#a6efb67c1b998ea7ffdc0a1e1b4252e62">empty</a>()) {</div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span>            <span class="keywordflow">throw</span> std::runtime_error(name + <span class="stringliteral">&quot; is empty after loading&quot;</span>);</div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span>        }</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>        std::cout &lt;&lt; name &lt;&lt; <span class="stringliteral">&quot; statistics:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- Shape: &quot;</span> &lt;&lt; m.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; m.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- Range: [&quot;</span> &lt;&lt; m.<a class="code hl_function" href="classMatrix.html#ad0b2d0782d21b8269d3dde66518bb66b">min</a>() &lt;&lt; <span class="stringliteral">&quot;, &quot;</span> &lt;&lt; m.<a class="code hl_function" href="classMatrix.html#ac0a0302810135d32909eaa819fd3d220">max</a>() &lt;&lt; <span class="stringliteral">&quot;]&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>        <span class="keywordflow">if</span> (std::isnan(m.<a class="code hl_function" href="classMatrix.html#ad0b2d0782d21b8269d3dde66518bb66b">min</a>()) || std::isnan(m.<a class="code hl_function" href="classMatrix.html#ac0a0302810135d32909eaa819fd3d220">max</a>()) || std::isinf(m.<a class="code hl_function" href="classMatrix.html#ad0b2d0782d21b8269d3dde66518bb66b">min</a>()) ||</div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>            std::isinf(m.<a class="code hl_function" href="classMatrix.html#ac0a0302810135d32909eaa819fd3d220">max</a>())) {</div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span>            <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;Invalid values in &quot;</span> + name + <span class="stringliteral">&quot; after loading&quot;</span>);</div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span>        }</div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>    };</div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span> </div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>    validate_matrix(attention-&gt;query_proj, <span class="stringliteral">&quot;Query projection&quot;</span>);</div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>    validate_matrix(attention-&gt;key_proj, <span class="stringliteral">&quot;Key projection&quot;</span>);</div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>    validate_matrix(attention-&gt;value_proj, <span class="stringliteral">&quot;Value projection&quot;</span>);</div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>    validate_matrix(attention-&gt;output_proj, <span class="stringliteral">&quot;Output projection&quot;</span>);</div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span> </div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;=== MultiHeadAttention::load END ===\n&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span>    <span class="keywordflow">return</span> attention;</div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span>}</div>
</div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span> </div>
<div class="foldopen" id="foldopen00442" data-start="{" data-end="}">
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#a5bb39f2850f5824fd23df006b4693299">  442</a></span><a class="code hl_function" href="classMultiHeadAttention.html#afd7c283ed2457ad7304567c897b3d877">MultiHeadAttention::MultiHeadAttention</a>(<span class="keywordtype">size_t</span> hidden_size_, <span class="keywordtype">size_t</span> num_heads_, <span class="keywordtype">size_t</span> head_dim_,</div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span>                                       <span class="keywordtype">float</span> dropout_prob_, <span class="keywordtype">bool</span> use_flash_, <span class="keywordtype">bool</span> use_rope_,</div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>                                       <span class="keywordtype">bool</span> use_sliding_window_, <span class="keywordtype">size_t</span> window_size_, <span class="keywordtype">bool</span> use_gqa_,</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span>                                       <span class="keywordtype">size_t</span> num_kv_heads_, <span class="keywordtype">size_t</span> max_seq_length_, <span class="keywordtype">bool</span> use_fp16)</div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span>    : num_heads(num_heads_), head_dim(head_dim_), hidden_size(hidden_size_),</div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>      dropout_prob(dropout_prob_), use_flash(use_flash_), use_rope(use_rope_),</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span>      use_sliding_window(use_sliding_window_), window_size(window_size_), use_gqa(use_gqa_),</div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span>      num_kv_heads(num_kv_heads_), max_seq_length(max_seq_length_),</div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span>      use_fp16_(use_fp16),</div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>      <span class="comment">// Initialize matrices with correct dimensions</span></div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>      query_proj(<a class="code hl_class" href="classMatrix.html">Matrix</a>(hidden_size_, num_heads_ * head_dim_)),</div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>      key_proj(<a class="code hl_class" href="classMatrix.html">Matrix</a>(hidden_size_, num_heads_ * head_dim_)),</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>      value_proj(<a class="code hl_class" href="classMatrix.html">Matrix</a>(hidden_size_, num_heads_ * head_dim_)),</div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>      output_proj(<a class="code hl_class" href="classMatrix.html">Matrix</a>(num_heads_ * head_dim_, hidden_size_)),</div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span>      <span class="comment">// Initialize bias vectors</span></div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span>      query_bias(<a class="code hl_class" href="classVector.html">FloatVector</a>(num_heads_ * head_dim_)),</div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span>      key_bias(<a class="code hl_class" href="classVector.html">FloatVector</a>(num_heads_ * head_dim_)),</div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span>      value_bias(<a class="code hl_class" href="classVector.html">FloatVector</a>(num_heads_ * head_dim_)), output_bias(<a class="code hl_class" href="classVector.html">FloatVector</a>(hidden_size_)),</div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span>      <span class="comment">// Initialize gradients with same dimensions as their parameters</span></div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>      query_proj_grad(<a class="code hl_class" href="classMatrix.html">Matrix</a>(hidden_size_, num_heads_ * head_dim_)),</div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>      key_proj_grad(<a class="code hl_class" href="classMatrix.html">Matrix</a>(hidden_size_, num_heads_ * head_dim_)),</div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span>      value_proj_grad(<a class="code hl_class" href="classMatrix.html">Matrix</a>(hidden_size_, num_heads_ * head_dim_)),</div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span>      output_proj_grad(<a class="code hl_class" href="classMatrix.html">Matrix</a>(num_heads_ * head_dim_, hidden_size_)),</div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span>      query_bias_grad(<a class="code hl_class" href="classVector.html">FloatVector</a>(num_heads_ * head_dim_)),</div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>      key_bias_grad(<a class="code hl_class" href="classVector.html">FloatVector</a>(num_heads_ * head_dim_)),</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>      value_bias_grad(<a class="code hl_class" href="classVector.html">FloatVector</a>(num_heads_ * head_dim_)),</div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span>      output_bias_grad(<a class="code hl_class" href="classVector.html">FloatVector</a>(hidden_size_)) {</div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span> </div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\n=== MultiHeadAttention::constructor START ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span> </div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span>    <span class="comment">// Print configuration</span></div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Configuration:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Hidden size: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">hidden_size</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Number of heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Head dimension: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Dropout probability: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#ad4b2bd9329b13739e3070253fa707abb">dropout_prob</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Use flash attention: &quot;</span> &lt;&lt; std::boolalpha &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a49435188dcf74478d543f7f4124bd25d">use_flash</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Use RoPE: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a6eaf4f61461419d9b2273d8ea5b61c8c">use_rope</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Use sliding window: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#aaffc8817085cfdbcdbebf858d6ff71ba">use_sliding_window</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Window size: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a25d0ca82bde81799ff028d4f4d276806">window_size</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Use GQA: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a58478592fe138677a9a9b923460dfaef">use_gqa</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Number of KV heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a5b61a3ff6c0d3debbf2c73e3a110aecc">num_kv_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span> </div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span>    <span class="comment">// Validate input dimensions</span></div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\nValidating dimensions...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">hidden_size</a> == 0 || <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> == 0 || <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> == 0) {</div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span>        <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;Invalid dimensions: hidden_size=&quot;</span> + std::to_string(<a class="code hl_variable" href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">hidden_size</a>) +</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>                                 <span class="stringliteral">&quot;, num_heads=&quot;</span> + std::to_string(<a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>) +</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>                                 <span class="stringliteral">&quot;, head_dim=&quot;</span> + std::to_string(<a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>));</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>    }</div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span> </div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">hidden_size</a> % <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> != 0) {</div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span>        <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;hidden_size must be divisible by num_heads&quot;</span>);</div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span>    }</div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Dimension validation passed&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span> </div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span>    <span class="comment">// Initialize weights with Xavier/Glorot initialization</span></div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\nInitializing weights...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span>    <span class="keywordtype">float</span> scale = std::sqrt(2.0f / (<a class="code hl_variable" href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">hidden_size</a> + <a class="code hl_variable" href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">hidden_size</a>));</div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span> </div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#a18362671ef7860ee292602e8a80fdfe3">query_proj</a>.<a class="code hl_function" href="classMatrix.html#a97f36647d60f005b37da2f51f21837d4">randomize</a>(-scale, scale);</div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#adccbc1658f1f13e00ea1a7cb71ec9030">key_proj</a>.<a class="code hl_function" href="classMatrix.html#a97f36647d60f005b37da2f51f21837d4">randomize</a>(-scale, scale);</div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#aad0999daf1477b120755a3413685812b">value_proj</a>.<a class="code hl_function" href="classMatrix.html#a97f36647d60f005b37da2f51f21837d4">randomize</a>(-scale, scale);</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#a4a1b86106c4351af679f4e0e2a8a0811">output_proj</a>.<a class="code hl_function" href="classMatrix.html#a97f36647d60f005b37da2f51f21837d4">randomize</a>(-scale, scale);</div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span> </div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span>    <span class="comment">// Initialize biases with zero</span></div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\nInitializing biases...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a0afc6064aba014f541fc9e2c4cf09841">query_bias</a>.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); i++)</div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a0afc6064aba014f541fc9e2c4cf09841">query_bias</a>[i] = 0.0f;</div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#ac034c448395ee5ccb2f55f801ccaec40">key_bias</a>.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); i++)</div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#ac034c448395ee5ccb2f55f801ccaec40">key_bias</a>[i] = 0.0f;</div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a43b9f09cb611795b1642d239aaa502b6">value_bias</a>.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); i++)</div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a43b9f09cb611795b1642d239aaa502b6">value_bias</a>[i] = 0.0f;</div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a3e04836c7b83bb0172fd3d9a120c8239">output_bias</a>.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); i++)</div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a3e04836c7b83bb0172fd3d9a120c8239">output_bias</a>[i] = 0.0f;</div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span> </div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span>    <span class="comment">// Initialize gradients to zero</span></div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a62c5dc456e39aa00650e69315fe86af3">query_proj_grad</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(); i++) {</div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a62c5dc456e39aa00650e69315fe86af3">query_proj_grad</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span>            <a class="code hl_variable" href="classMultiHeadAttention.html#a62c5dc456e39aa00650e69315fe86af3">query_proj_grad</a>(i, j) = 0.0f;</div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span>            <a class="code hl_variable" href="classMultiHeadAttention.html#aded8e7c09f874cc1aa73f9da805a3ec6">key_proj_grad</a>(i, j) = 0.0f;</div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span>            <a class="code hl_variable" href="classMultiHeadAttention.html#a8637aa0a25d31fc7f4713f916bb1f043">value_proj_grad</a>(i, j) = 0.0f;</div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span>            <a class="code hl_variable" href="classMultiHeadAttention.html#a4385a8aebf34df120d848956d8f510c5">output_proj_grad</a>(i, j) = 0.0f;</div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span>        }</div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span>    }</div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span> </div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a944d2e4a686b408e94758c7458888f47">query_bias_grad</a>.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); i++)</div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno">  529</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a944d2e4a686b408e94758c7458888f47">query_bias_grad</a>[i] = 0.0f;</div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno">  530</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a872be590c370844a88aff0705d1cba72">key_bias_grad</a>.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); i++)</div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno">  531</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a872be590c370844a88aff0705d1cba72">key_bias_grad</a>[i] = 0.0f;</div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno">  532</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#afa3b408cc8580772c3bdc32b5e25fe07">value_bias_grad</a>.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); i++)</div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno">  533</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#afa3b408cc8580772c3bdc32b5e25fe07">value_bias_grad</a>[i] = 0.0f;</div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a891d285712cdbb98de1b453c58c23cc4">output_bias_grad</a>.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); i++)</div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a891d285712cdbb98de1b453c58c23cc4">output_bias_grad</a>[i] = 0.0f;</div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno">  536</span> </div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno">  537</span>    <span class="comment">// Validate initialization</span></div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\nValidating initialization...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span>    <span class="keyword">auto</span> validate_matrix = [](<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; m, <span class="keyword">const</span> std::string&amp; name) {</div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span>        <span class="keywordflow">if</span> (m.<a class="code hl_function" href="classMatrix.html#a6efb67c1b998ea7ffdc0a1e1b4252e62">empty</a>()) {</div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span>            <span class="keywordflow">throw</span> std::runtime_error(name + <span class="stringliteral">&quot; is empty after initialization&quot;</span>);</div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span>        }</div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span>        std::cout &lt;&lt; name &lt;&lt; <span class="stringliteral">&quot; statistics:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- Shape: &quot;</span> &lt;&lt; m.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; m.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;- Range: [&quot;</span> &lt;&lt; m.<a class="code hl_function" href="classMatrix.html#ad0b2d0782d21b8269d3dde66518bb66b">min</a>() &lt;&lt; <span class="stringliteral">&quot;, &quot;</span> &lt;&lt; m.<a class="code hl_function" href="classMatrix.html#ac0a0302810135d32909eaa819fd3d220">max</a>() &lt;&lt; <span class="stringliteral">&quot;]&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno">  546</span>        <span class="keywordflow">if</span> (std::isnan(m.<a class="code hl_function" href="classMatrix.html#ad0b2d0782d21b8269d3dde66518bb66b">min</a>()) || std::isnan(m.<a class="code hl_function" href="classMatrix.html#ac0a0302810135d32909eaa819fd3d220">max</a>()) || std::isinf(m.<a class="code hl_function" href="classMatrix.html#ad0b2d0782d21b8269d3dde66518bb66b">min</a>()) ||</div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span>            std::isinf(m.<a class="code hl_function" href="classMatrix.html#ac0a0302810135d32909eaa819fd3d220">max</a>())) {</div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno">  548</span>            <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;Invalid values in &quot;</span> + name + <span class="stringliteral">&quot; after initialization&quot;</span>);</div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span>        }</div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span>    };</div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span> </div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span>    validate_matrix(<a class="code hl_variable" href="classMultiHeadAttention.html#a18362671ef7860ee292602e8a80fdfe3">query_proj</a>, <span class="stringliteral">&quot;Query projection&quot;</span>);</div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span>    validate_matrix(<a class="code hl_variable" href="classMultiHeadAttention.html#adccbc1658f1f13e00ea1a7cb71ec9030">key_proj</a>, <span class="stringliteral">&quot;Key projection&quot;</span>);</div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span>    validate_matrix(<a class="code hl_variable" href="classMultiHeadAttention.html#aad0999daf1477b120755a3413685812b">value_proj</a>, <span class="stringliteral">&quot;Value projection&quot;</span>);</div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span>    validate_matrix(<a class="code hl_variable" href="classMultiHeadAttention.html#a4a1b86106c4351af679f4e0e2a8a0811">output_proj</a>, <span class="stringliteral">&quot;Output projection&quot;</span>);</div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span>    validate_matrix(<a class="code hl_variable" href="classMultiHeadAttention.html#a62c5dc456e39aa00650e69315fe86af3">query_proj_grad</a>, <span class="stringliteral">&quot;Query projection gradient&quot;</span>);</div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span>    validate_matrix(<a class="code hl_variable" href="classMultiHeadAttention.html#aded8e7c09f874cc1aa73f9da805a3ec6">key_proj_grad</a>, <span class="stringliteral">&quot;Key projection gradient&quot;</span>);</div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span>    validate_matrix(<a class="code hl_variable" href="classMultiHeadAttention.html#a8637aa0a25d31fc7f4713f916bb1f043">value_proj_grad</a>, <span class="stringliteral">&quot;Value projection gradient&quot;</span>);</div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span>    validate_matrix(<a class="code hl_variable" href="classMultiHeadAttention.html#a4385a8aebf34df120d848956d8f510c5">output_proj_grad</a>, <span class="stringliteral">&quot;Output projection gradient&quot;</span>);</div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span> </div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;=== MultiHeadAttention::constructor END ===\n&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno">  562</span> </div>
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno">  563</span>    <a class="code hl_function" href="classMultiHeadAttention.html#a6cc7e11046066e5d752d9112c56d16f2">initialize_rope_cache</a>(max_seq_length_, <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>);</div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span>}</div>
</div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span> </div>
<div class="foldopen" id="foldopen00566" data-start="{" data-end="}">
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#aa63f2eb55c928afcbaabe2bed9b5fe9f">  566</a></span><a class="code hl_class" href="classMatrix.html">Matrix</a> <a class="code hl_function" href="classMultiHeadAttention.html#aa63f2eb55c928afcbaabe2bed9b5fe9f">MultiHeadAttention::standard_attention</a>(<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; Q, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; K, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; V,</div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span>                                              <span class="keyword">const</span> <a class="code hl_class" href="classAttentionMask.html">AttentionMask</a>&amp; mask) {</div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;\n=== MultiHeadAttention::standard_attention START ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span> </div>
<div class="line"><a id="l00570" name="l00570"></a><span class="lineno">  570</span>    <span class="comment">// Calculate dimensions</span></div>
<div class="line"><a id="l00571" name="l00571"></a><span class="lineno">  571</span>    <span class="keywordtype">size_t</span> seq_len = Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>();</div>
<div class="line"><a id="l00572" name="l00572"></a><span class="lineno">  572</span>    <span class="keywordtype">size_t</span> head_size = Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() / <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>;</div>
<div class="line"><a id="l00573" name="l00573"></a><span class="lineno">  573</span> </div>
<div class="line"><a id="l00574" name="l00574"></a><span class="lineno">  574</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Dimensions:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00575" name="l00575"></a><span class="lineno">  575</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Sequence length: &quot;</span> &lt;&lt; seq_len &lt;&lt; std::endl;</div>
<div class="line"><a id="l00576" name="l00576"></a><span class="lineno">  576</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Head size: &quot;</span> &lt;&lt; head_size &lt;&lt; std::endl;</div>
<div class="line"><a id="l00577" name="l00577"></a><span class="lineno">  577</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- Number of heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00578" name="l00578"></a><span class="lineno">  578</span> </div>
<div class="line"><a id="l00579" name="l00579"></a><span class="lineno">  579</span>    <span class="comment">// Always create a proper mask</span></div>
<div class="line"><a id="l00580" name="l00580"></a><span class="lineno">  580</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> effective_mask(seq_len, seq_len, 1.0f);</div>
<div class="line"><a id="l00581" name="l00581"></a><span class="lineno">  581</span> </div>
<div class="line"><a id="l00582" name="l00582"></a><span class="lineno">  582</span>    <span class="keywordflow">if</span> (!mask.<a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>.<a class="code hl_function" href="classMatrix.html#a6efb67c1b998ea7ffdc0a1e1b4252e62">empty</a>()) {</div>
<div class="line"><a id="l00583" name="l00583"></a><span class="lineno">  583</span>        effective_mask = mask.<a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>;</div>
<div class="line"><a id="l00584" name="l00584"></a><span class="lineno">  584</span>    }</div>
<div class="line"><a id="l00585" name="l00585"></a><span class="lineno">  585</span> </div>
<div class="line"><a id="l00586" name="l00586"></a><span class="lineno">  586</span>    <span class="comment">// First reshape inputs to separate heads</span></div>
<div class="line"><a id="l00587" name="l00587"></a><span class="lineno">  587</span>    <a class="code hl_class" href="classTensor.html">Tensor</a> Q_4d = <a class="code hl_function" href="classMultiHeadAttention.html#ad58475dba6a9acf0f788a069807ca678">reshape_for_attention</a>(Q, 1, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, seq_len, head_size);</div>
<div class="line"><a id="l00588" name="l00588"></a><span class="lineno">  588</span>    <a class="code hl_class" href="classTensor.html">Tensor</a> K_4d = <a class="code hl_function" href="classMultiHeadAttention.html#ad58475dba6a9acf0f788a069807ca678">reshape_for_attention</a>(K, 1, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, seq_len, head_size);</div>
<div class="line"><a id="l00589" name="l00589"></a><span class="lineno">  589</span>    <a class="code hl_class" href="classTensor.html">Tensor</a> V_4d = <a class="code hl_function" href="classMultiHeadAttention.html#ad58475dba6a9acf0f788a069807ca678">reshape_for_attention</a>(V, 1, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, seq_len, head_size);</div>
<div class="line"><a id="l00590" name="l00590"></a><span class="lineno">  590</span> </div>
<div class="line"><a id="l00591" name="l00591"></a><span class="lineno">  591</span>    <span class="comment">// Process each head separately with improved numerical stability</span></div>
<div class="line"><a id="l00592" name="l00592"></a><span class="lineno">  592</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> final_output(seq_len, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> * head_size);</div>
<div class="line"><a id="l00593" name="l00593"></a><span class="lineno">  593</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> scale = 1.0f / std::sqrt(<span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(head_size));</div>
<div class="line"><a id="l00594" name="l00594"></a><span class="lineno">  594</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> max_score = 100.0f; <span class="comment">// Prevent exp overflow</span></div>
<div class="line"><a id="l00595" name="l00595"></a><span class="lineno">  595</span> </div>
<div class="line"><a id="l00596" name="l00596"></a><span class="lineno">  596</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> h = 0; h &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>; ++h) {</div>
<div class="line"><a id="l00597" name="l00597"></a><span class="lineno">  597</span>        <span class="comment">// Extract matrices for current head</span></div>
<div class="line"><a id="l00598" name="l00598"></a><span class="lineno">  598</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> Q_head(seq_len, head_size);</div>
<div class="line"><a id="l00599" name="l00599"></a><span class="lineno">  599</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> K_head(seq_len, head_size);</div>
<div class="line"><a id="l00600" name="l00600"></a><span class="lineno">  600</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> V_head(seq_len, head_size);</div>
<div class="line"><a id="l00601" name="l00601"></a><span class="lineno">  601</span> </div>
<div class="line"><a id="l00602" name="l00602"></a><span class="lineno">  602</span>        <span class="comment">// Copy data for current head</span></div>
<div class="line"><a id="l00603" name="l00603"></a><span class="lineno">  603</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> s = 0; s &lt; seq_len; ++s) {</div>
<div class="line"><a id="l00604" name="l00604"></a><span class="lineno">  604</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; head_size; ++d) {</div>
<div class="line"><a id="l00605" name="l00605"></a><span class="lineno">  605</span>                Q_head(s, d) = Q_4d.<a class="code hl_function" href="classTensor.html#a5660c81a5a0ff70a748f818c07010c87">at</a>(0, h, s, d);</div>
<div class="line"><a id="l00606" name="l00606"></a><span class="lineno">  606</span>                K_head(s, d) = K_4d.<a class="code hl_function" href="classTensor.html#a5660c81a5a0ff70a748f818c07010c87">at</a>(0, h, s, d);</div>
<div class="line"><a id="l00607" name="l00607"></a><span class="lineno">  607</span>                V_head(s, d) = V_4d.<a class="code hl_function" href="classTensor.html#a5660c81a5a0ff70a748f818c07010c87">at</a>(0, h, s, d);</div>
<div class="line"><a id="l00608" name="l00608"></a><span class="lineno">  608</span>            }</div>
<div class="line"><a id="l00609" name="l00609"></a><span class="lineno">  609</span>        }</div>
<div class="line"><a id="l00610" name="l00610"></a><span class="lineno">  610</span> </div>
<div class="line"><a id="l00611" name="l00611"></a><span class="lineno">  611</span>        <span class="comment">// Compute attention scores with numerical stability</span></div>
<div class="line"><a id="l00612" name="l00612"></a><span class="lineno">  612</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> scores = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(Q_head, K_head.<a class="code hl_function" href="classMatrix.html#a759661b75b9681f3a89ff75e27933b3a">transpose</a>());</div>
<div class="line"><a id="l00613" name="l00613"></a><span class="lineno">  613</span>        scores *= scale;</div>
<div class="line"><a id="l00614" name="l00614"></a><span class="lineno">  614</span> </div>
<div class="line"><a id="l00615" name="l00615"></a><span class="lineno">  615</span>        <span class="comment">// Apply mask and numerical stability improvements</span></div>
<div class="line"><a id="l00616" name="l00616"></a><span class="lineno">  616</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; seq_len; ++i) {</div>
<div class="line"><a id="l00617" name="l00617"></a><span class="lineno">  617</span>            <span class="comment">// Find max for numerical stability in softmax</span></div>
<div class="line"><a id="l00618" name="l00618"></a><span class="lineno">  618</span>            <span class="keywordtype">float</span> row_max = -std::numeric_limits&lt;float&gt;::infinity();</div>
<div class="line"><a id="l00619" name="l00619"></a><span class="lineno">  619</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; seq_len; ++j) {</div>
<div class="line"><a id="l00620" name="l00620"></a><span class="lineno">  620</span>                <span class="keywordflow">if</span> (effective_mask(i, j) == 0.0f) {</div>
<div class="line"><a id="l00621" name="l00621"></a><span class="lineno">  621</span>                    scores(i, j) = -std::numeric_limits&lt;float&gt;::infinity();</div>
<div class="line"><a id="l00622" name="l00622"></a><span class="lineno">  622</span>                } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00623" name="l00623"></a><span class="lineno">  623</span>                    scores(i, j) = std::min(scores(i, j), max_score);</div>
<div class="line"><a id="l00624" name="l00624"></a><span class="lineno">  624</span>                    row_max = std::max(row_max, scores(i, j));</div>
<div class="line"><a id="l00625" name="l00625"></a><span class="lineno">  625</span>                }</div>
<div class="line"><a id="l00626" name="l00626"></a><span class="lineno">  626</span>            }</div>
<div class="line"><a id="l00627" name="l00627"></a><span class="lineno">  627</span> </div>
<div class="line"><a id="l00628" name="l00628"></a><span class="lineno">  628</span>            <span class="comment">// Compute softmax with improved numerical stability</span></div>
<div class="line"><a id="l00629" name="l00629"></a><span class="lineno">  629</span>            <span class="keywordtype">float</span> sum_exp = 0.0f;</div>
<div class="line"><a id="l00630" name="l00630"></a><span class="lineno">  630</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; seq_len; ++j) {</div>
<div class="line"><a id="l00631" name="l00631"></a><span class="lineno">  631</span>                <span class="keywordflow">if</span> (scores(i, j) != -std::numeric_limits&lt;float&gt;::infinity()) {</div>
<div class="line"><a id="l00632" name="l00632"></a><span class="lineno">  632</span>                    scores(i, j) = std::exp(scores(i, j) - row_max);</div>
<div class="line"><a id="l00633" name="l00633"></a><span class="lineno">  633</span>                    sum_exp += scores(i, j);</div>
<div class="line"><a id="l00634" name="l00634"></a><span class="lineno">  634</span>                } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00635" name="l00635"></a><span class="lineno">  635</span>                    scores(i, j) = 0.0f;</div>
<div class="line"><a id="l00636" name="l00636"></a><span class="lineno">  636</span>                }</div>
<div class="line"><a id="l00637" name="l00637"></a><span class="lineno">  637</span>            }</div>
<div class="line"><a id="l00638" name="l00638"></a><span class="lineno">  638</span> </div>
<div class="line"><a id="l00639" name="l00639"></a><span class="lineno">  639</span>            <span class="comment">// Normalize with careful handling of small values</span></div>
<div class="line"><a id="l00640" name="l00640"></a><span class="lineno">  640</span>            <span class="keyword">const</span> <span class="keywordtype">float</span> eps = 1e-6f;</div>
<div class="line"><a id="l00641" name="l00641"></a><span class="lineno">  641</span>            <span class="keywordflow">if</span> (sum_exp &lt; eps)</div>
<div class="line"><a id="l00642" name="l00642"></a><span class="lineno">  642</span>                sum_exp = eps;</div>
<div class="line"><a id="l00643" name="l00643"></a><span class="lineno">  643</span> </div>
<div class="line"><a id="l00644" name="l00644"></a><span class="lineno">  644</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; seq_len; ++j) {</div>
<div class="line"><a id="l00645" name="l00645"></a><span class="lineno">  645</span>                scores(i, j) /= sum_exp;</div>
<div class="line"><a id="l00646" name="l00646"></a><span class="lineno">  646</span>            }</div>
<div class="line"><a id="l00647" name="l00647"></a><span class="lineno">  647</span>        }</div>
<div class="line"><a id="l00648" name="l00648"></a><span class="lineno">  648</span> </div>
<div class="line"><a id="l00649" name="l00649"></a><span class="lineno">  649</span>        <span class="comment">// Compute attention output for this head</span></div>
<div class="line"><a id="l00650" name="l00650"></a><span class="lineno">  650</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> head_output = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(scores, V_head);</div>
<div class="line"><a id="l00651" name="l00651"></a><span class="lineno">  651</span> </div>
<div class="line"><a id="l00652" name="l00652"></a><span class="lineno">  652</span>        <span class="comment">// Store this head&#39;s output in the final result</span></div>
<div class="line"><a id="l00653" name="l00653"></a><span class="lineno">  653</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> s = 0; s &lt; seq_len; ++s) {</div>
<div class="line"><a id="l00654" name="l00654"></a><span class="lineno">  654</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; head_size; ++d) {</div>
<div class="line"><a id="l00655" name="l00655"></a><span class="lineno">  655</span>                final_output(s, h * head_size + d) = head_output(s, d);</div>
<div class="line"><a id="l00656" name="l00656"></a><span class="lineno">  656</span>            }</div>
<div class="line"><a id="l00657" name="l00657"></a><span class="lineno">  657</span>        }</div>
<div class="line"><a id="l00658" name="l00658"></a><span class="lineno">  658</span>    }</div>
<div class="line"><a id="l00659" name="l00659"></a><span class="lineno">  659</span> </div>
<div class="line"><a id="l00660" name="l00660"></a><span class="lineno">  660</span>    <span class="keywordflow">return</span> final_output;</div>
<div class="line"><a id="l00661" name="l00661"></a><span class="lineno">  661</span>}</div>
</div>
<div class="line"><a id="l00662" name="l00662"></a><span class="lineno">  662</span> </div>
<div class="foldopen" id="foldopen00663" data-start="{" data-end="}">
<div class="line"><a id="l00663" name="l00663"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#a0d5c79966001a4f69b95c8fdcad85e2b">  663</a></span><a class="code hl_class" href="classMatrix.html">Matrix</a> <a class="code hl_function" href="classMultiHeadAttention.html#a0d5c79966001a4f69b95c8fdcad85e2b">MultiHeadAttention::backward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; grad_output, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; input,</div>
<div class="line"><a id="l00664" name="l00664"></a><span class="lineno">  664</span>                                    <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; target_distribution) {</div>
<div class="line"><a id="l00665" name="l00665"></a><span class="lineno">  665</span>    <span class="comment">// Get use_fp16 from member variable instead of global config</span></div>
<div class="line"><a id="l00666" name="l00666"></a><span class="lineno">  666</span>    <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">bool</span> use_fp16 = <a class="code hl_variable" href="classMultiHeadAttention.html#a4314826233aeaa0ba472897dbb1ee7e9">use_fp16_</a>;</div>
<div class="line"><a id="l00667" name="l00667"></a><span class="lineno">  667</span>    </div>
<div class="line"><a id="l00668" name="l00668"></a><span class="lineno">  668</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> grad = grad_output;</div>
<div class="line"><a id="l00669" name="l00669"></a><span class="lineno">  669</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> input_matrix = input;</div>
<div class="line"><a id="l00670" name="l00670"></a><span class="lineno">  670</span>    </div>
<div class="line"><a id="l00671" name="l00671"></a><span class="lineno">  671</span>    <span class="keywordflow">if</span> (use_fp16) {</div>
<div class="line"><a id="l00672" name="l00672"></a><span class="lineno">  672</span>        <a class="code hl_function" href="classHalfPrecisionTraining.html#a82deaaee41c1b5d49adf8049b9a0d2e3">HalfPrecisionTraining::convert_to_fp16</a>(grad);</div>
<div class="line"><a id="l00673" name="l00673"></a><span class="lineno">  673</span>        <a class="code hl_function" href="classHalfPrecisionTraining.html#a82deaaee41c1b5d49adf8049b9a0d2e3">HalfPrecisionTraining::convert_to_fp16</a>(input_matrix);</div>
<div class="line"><a id="l00674" name="l00674"></a><span class="lineno">  674</span>    }</div>
<div class="line"><a id="l00675" name="l00675"></a><span class="lineno">  675</span> </div>
<div class="line"><a id="l00676" name="l00676"></a><span class="lineno">  676</span>    <a class="code hl_function" href="classMultiHeadAttention.html#a595e7485ec3665e5dae0b13e820a529b">validate_dimensions</a>(grad, input_matrix, target_distribution);</div>
<div class="line"><a id="l00677" name="l00677"></a><span class="lineno">  677</span> </div>
<div class="line"><a id="l00678" name="l00678"></a><span class="lineno">  678</span>    <span class="comment">// Initialize gradients if not already done</span></div>
<div class="line"><a id="l00679" name="l00679"></a><span class="lineno">  679</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classMultiHeadAttention.html#a62c5dc456e39aa00650e69315fe86af3">query_proj_grad</a>.<a class="code hl_function" href="classMatrix.html#a6efb67c1b998ea7ffdc0a1e1b4252e62">empty</a>()) {</div>
<div class="line"><a id="l00680" name="l00680"></a><span class="lineno">  680</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a62c5dc456e39aa00650e69315fe86af3">query_proj_grad</a> = <a class="code hl_class" href="classMatrix.html">Matrix</a>(<a class="code hl_variable" href="classMultiHeadAttention.html#a18362671ef7860ee292602e8a80fdfe3">query_proj</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(), <a class="code hl_variable" href="classMultiHeadAttention.html#a18362671ef7860ee292602e8a80fdfe3">query_proj</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(), 0.0f);</div>
<div class="line"><a id="l00681" name="l00681"></a><span class="lineno">  681</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#aded8e7c09f874cc1aa73f9da805a3ec6">key_proj_grad</a> = <a class="code hl_class" href="classMatrix.html">Matrix</a>(<a class="code hl_variable" href="classMultiHeadAttention.html#adccbc1658f1f13e00ea1a7cb71ec9030">key_proj</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(), <a class="code hl_variable" href="classMultiHeadAttention.html#adccbc1658f1f13e00ea1a7cb71ec9030">key_proj</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(), 0.0f);</div>
<div class="line"><a id="l00682" name="l00682"></a><span class="lineno">  682</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a8637aa0a25d31fc7f4713f916bb1f043">value_proj_grad</a> = <a class="code hl_class" href="classMatrix.html">Matrix</a>(<a class="code hl_variable" href="classMultiHeadAttention.html#aad0999daf1477b120755a3413685812b">value_proj</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(), <a class="code hl_variable" href="classMultiHeadAttention.html#aad0999daf1477b120755a3413685812b">value_proj</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(), 0.0f);</div>
<div class="line"><a id="l00683" name="l00683"></a><span class="lineno">  683</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a4385a8aebf34df120d848956d8f510c5">output_proj_grad</a> = <a class="code hl_class" href="classMatrix.html">Matrix</a>(<a class="code hl_variable" href="classMultiHeadAttention.html#a4a1b86106c4351af679f4e0e2a8a0811">output_proj</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(), <a class="code hl_variable" href="classMultiHeadAttention.html#a4a1b86106c4351af679f4e0e2a8a0811">output_proj</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(), 0.0f);</div>
<div class="line"><a id="l00684" name="l00684"></a><span class="lineno">  684</span>    }</div>
<div class="line"><a id="l00685" name="l00685"></a><span class="lineno">  685</span> </div>
<div class="line"><a id="l00686" name="l00686"></a><span class="lineno">  686</span>    <span class="comment">// Compute gradients for attention mechanism</span></div>
<div class="line"><a id="l00687" name="l00687"></a><span class="lineno">  687</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> d_query = <a class="code hl_function" href="classMultiHeadAttention.html#aa153e5d1204e9e40db741b979b8da86d">compute_query_gradients</a>(grad, input_matrix);</div>
<div class="line"><a id="l00688" name="l00688"></a><span class="lineno">  688</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> d_key = <a class="code hl_function" href="classMultiHeadAttention.html#a2af0984f2e552f9bbad0eb9a4f33e1dc">compute_key_gradients</a>(grad, input_matrix);</div>
<div class="line"><a id="l00689" name="l00689"></a><span class="lineno">  689</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> d_value = <a class="code hl_function" href="classMultiHeadAttention.html#afb26ebaa99dac3ec111eeeb60baf96cf">compute_value_gradients</a>(grad, input_matrix);</div>
<div class="line"><a id="l00690" name="l00690"></a><span class="lineno">  690</span> </div>
<div class="line"><a id="l00691" name="l00691"></a><span class="lineno">  691</span>    <span class="comment">// Combine gradients</span></div>
<div class="line"><a id="l00692" name="l00692"></a><span class="lineno">  692</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> d_input = <a class="code hl_function" href="classMultiHeadAttention.html#a6e2075c78c6a20f11ea661d31ecffa32">combine_gradients</a>(d_query, d_key, d_value);</div>
<div class="line"><a id="l00693" name="l00693"></a><span class="lineno">  693</span> </div>
<div class="line"><a id="l00694" name="l00694"></a><span class="lineno">  694</span>    <span class="comment">// Update projection gradients</span></div>
<div class="line"><a id="l00695" name="l00695"></a><span class="lineno">  695</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#a62c5dc456e39aa00650e69315fe86af3">query_proj_grad</a> += <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(input_matrix.<a class="code hl_function" href="classMatrix.html#a759661b75b9681f3a89ff75e27933b3a">transpose</a>(), d_query);</div>
<div class="line"><a id="l00696" name="l00696"></a><span class="lineno">  696</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#aded8e7c09f874cc1aa73f9da805a3ec6">key_proj_grad</a> += <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(input_matrix.<a class="code hl_function" href="classMatrix.html#a759661b75b9681f3a89ff75e27933b3a">transpose</a>(), d_key);</div>
<div class="line"><a id="l00697" name="l00697"></a><span class="lineno">  697</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#a8637aa0a25d31fc7f4713f916bb1f043">value_proj_grad</a> += <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(input_matrix.<a class="code hl_function" href="classMatrix.html#a759661b75b9681f3a89ff75e27933b3a">transpose</a>(), d_value);</div>
<div class="line"><a id="l00698" name="l00698"></a><span class="lineno">  698</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#a4385a8aebf34df120d848956d8f510c5">output_proj_grad</a> += <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(grad.<a class="code hl_function" href="classMatrix.html#a759661b75b9681f3a89ff75e27933b3a">transpose</a>(), input_matrix);</div>
<div class="line"><a id="l00699" name="l00699"></a><span class="lineno">  699</span> </div>
<div class="line"><a id="l00700" name="l00700"></a><span class="lineno">  700</span>    <span class="comment">// Update bias gradients</span></div>
<div class="line"><a id="l00701" name="l00701"></a><span class="lineno">  701</span>    <a class="code hl_class" href="classVector.html">Vector</a> d_query_bias = d_query.<a class="code hl_function" href="classMatrix.html#a95e1fcffce26339f95f1353a4193aac2">row_sum</a>();</div>
<div class="line"><a id="l00702" name="l00702"></a><span class="lineno">  702</span>    <a class="code hl_class" href="classVector.html">Vector</a> d_key_bias = d_key.<a class="code hl_function" href="classMatrix.html#a95e1fcffce26339f95f1353a4193aac2">row_sum</a>();</div>
<div class="line"><a id="l00703" name="l00703"></a><span class="lineno">  703</span>    <a class="code hl_class" href="classVector.html">Vector</a> d_value_bias = d_value.<a class="code hl_function" href="classMatrix.html#a95e1fcffce26339f95f1353a4193aac2">row_sum</a>();</div>
<div class="line"><a id="l00704" name="l00704"></a><span class="lineno">  704</span>    <a class="code hl_class" href="classVector.html">Vector</a> d_output_bias = grad.<a class="code hl_function" href="classMatrix.html#a95e1fcffce26339f95f1353a4193aac2">row_sum</a>();</div>
<div class="line"><a id="l00705" name="l00705"></a><span class="lineno">  705</span> </div>
<div class="line"><a id="l00706" name="l00706"></a><span class="lineno">  706</span>    <span class="comment">// Update bias gradients element by element</span></div>
<div class="line"><a id="l00707" name="l00707"></a><span class="lineno">  707</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a944d2e4a686b408e94758c7458888f47">query_bias_grad</a>.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); ++i) {</div>
<div class="line"><a id="l00708" name="l00708"></a><span class="lineno">  708</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a944d2e4a686b408e94758c7458888f47">query_bias_grad</a>[i] += d_query_bias[i];</div>
<div class="line"><a id="l00709" name="l00709"></a><span class="lineno">  709</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a872be590c370844a88aff0705d1cba72">key_bias_grad</a>[i] += d_key_bias[i];</div>
<div class="line"><a id="l00710" name="l00710"></a><span class="lineno">  710</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#afa3b408cc8580772c3bdc32b5e25fe07">value_bias_grad</a>[i] += d_value_bias[i];</div>
<div class="line"><a id="l00711" name="l00711"></a><span class="lineno">  711</span>    }</div>
<div class="line"><a id="l00712" name="l00712"></a><span class="lineno">  712</span> </div>
<div class="line"><a id="l00713" name="l00713"></a><span class="lineno">  713</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a891d285712cdbb98de1b453c58c23cc4">output_bias_grad</a>.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); ++i) {</div>
<div class="line"><a id="l00714" name="l00714"></a><span class="lineno">  714</span>        <a class="code hl_variable" href="classMultiHeadAttention.html#a891d285712cdbb98de1b453c58c23cc4">output_bias_grad</a>[i] += d_output_bias[i];</div>
<div class="line"><a id="l00715" name="l00715"></a><span class="lineno">  715</span>    }</div>
<div class="line"><a id="l00716" name="l00716"></a><span class="lineno">  716</span> </div>
<div class="line"><a id="l00717" name="l00717"></a><span class="lineno">  717</span>    <span class="comment">// Convert gradients back to FP32 before returning</span></div>
<div class="line"><a id="l00718" name="l00718"></a><span class="lineno">  718</span>    <span class="keywordflow">if</span> (use_fp16) {</div>
<div class="line"><a id="l00719" name="l00719"></a><span class="lineno">  719</span>        <a class="code hl_function" href="classHalfPrecisionTraining.html#aa968c90058884f141bdc068b6ff64b9b">HalfPrecisionTraining::convert_to_fp32</a>(grad);</div>
<div class="line"><a id="l00720" name="l00720"></a><span class="lineno">  720</span>    }</div>
<div class="line"><a id="l00721" name="l00721"></a><span class="lineno">  721</span> </div>
<div class="line"><a id="l00722" name="l00722"></a><span class="lineno">  722</span>    <span class="keywordflow">return</span> d_input;</div>
<div class="line"><a id="l00723" name="l00723"></a><span class="lineno">  723</span>}</div>
</div>
<div class="line"><a id="l00724" name="l00724"></a><span class="lineno">  724</span> </div>
<div class="foldopen" id="foldopen00725" data-start="{" data-end="}">
<div class="line"><a id="l00725" name="l00725"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#ad58475dba6a9acf0f788a069807ca678">  725</a></span><a class="code hl_class" href="classTensor.html">Tensor</a> <a class="code hl_function" href="classMultiHeadAttention.html#ad58475dba6a9acf0f788a069807ca678">MultiHeadAttention::reshape_for_attention</a>(<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; x, <span class="keywordtype">size_t</span> batch_size,</div>
<div class="line"><a id="l00726" name="l00726"></a><span class="lineno">  726</span>                                                 <span class="keywordtype">size_t</span> num_heads, <span class="keywordtype">size_t</span> seq_len,</div>
<div class="line"><a id="l00727" name="l00727"></a><span class="lineno">  727</span>                                                 <span class="keywordtype">size_t</span> head_size)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00728" name="l00728"></a><span class="lineno">  728</span>    <span class="comment">// Create a 4D tensor with shape [batch_size, num_heads, seq_len, head_size]</span></div>
<div class="line"><a id="l00729" name="l00729"></a><span class="lineno">  729</span>    <a class="code hl_class" href="classTensor.html">Tensor</a> reshaped(batch_size, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, seq_len, head_size);</div>
<div class="line"><a id="l00730" name="l00730"></a><span class="lineno">  730</span> </div>
<div class="line"><a id="l00731" name="l00731"></a><span class="lineno">  731</span>    <span class="comment">// Copy and reshape the data</span></div>
<div class="line"><a id="l00732" name="l00732"></a><span class="lineno">  732</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> b = 0; b &lt; batch_size; ++b) {</div>
<div class="line"><a id="l00733" name="l00733"></a><span class="lineno">  733</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> h = 0; h &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>; ++h) {</div>
<div class="line"><a id="l00734" name="l00734"></a><span class="lineno">  734</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> s = 0; s &lt; seq_len; ++s) {</div>
<div class="line"><a id="l00735" name="l00735"></a><span class="lineno">  735</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; head_size; ++d) {</div>
<div class="line"><a id="l00736" name="l00736"></a><span class="lineno">  736</span>                    <span class="comment">// Correct indexing for the input matrix</span></div>
<div class="line"><a id="l00737" name="l00737"></a><span class="lineno">  737</span>                    <span class="keywordtype">size_t</span> flat_idx = s * x.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() + h * head_size + d;</div>
<div class="line"><a id="l00738" name="l00738"></a><span class="lineno">  738</span>                    reshaped.<a class="code hl_function" href="classTensor.html#a5660c81a5a0ff70a748f818c07010c87">at</a>(b, h, s, d) = x.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[flat_idx];</div>
<div class="line"><a id="l00739" name="l00739"></a><span class="lineno">  739</span>                }</div>
<div class="line"><a id="l00740" name="l00740"></a><span class="lineno">  740</span>            }</div>
<div class="line"><a id="l00741" name="l00741"></a><span class="lineno">  741</span>        }</div>
<div class="line"><a id="l00742" name="l00742"></a><span class="lineno">  742</span>    }</div>
<div class="line"><a id="l00743" name="l00743"></a><span class="lineno">  743</span>    <span class="keywordflow">return</span> reshaped;</div>
<div class="line"><a id="l00744" name="l00744"></a><span class="lineno">  744</span>}</div>
</div>
<div class="line"><a id="l00745" name="l00745"></a><span class="lineno">  745</span> </div>
<div class="foldopen" id="foldopen00746" data-start="{" data-end="}">
<div class="line"><a id="l00746" name="l00746"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#aff569533c7e7f11a7fa4b6ba1662efc5">  746</a></span><a class="code hl_class" href="classMatrix.html">Matrix</a> <a class="code hl_function" href="classMultiHeadAttention.html#aff569533c7e7f11a7fa4b6ba1662efc5">MultiHeadAttention::reshape_from_attention</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor</a>&amp; x, <span class="keywordtype">size_t</span> batch_size,</div>
<div class="line"><a id="l00747" name="l00747"></a><span class="lineno">  747</span>                                                  <span class="keywordtype">size_t</span> hidden_size)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00748" name="l00748"></a><span class="lineno">  748</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;=== reshape_from_attention START ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00749" name="l00749"></a><span class="lineno">  749</span> </div>
<div class="line"><a id="l00750" name="l00750"></a><span class="lineno">  750</span>    <span class="comment">// Get dimensions from tensor</span></div>
<div class="line"><a id="l00751" name="l00751"></a><span class="lineno">  751</span>    <span class="keyword">const</span> <span class="keyword">auto</span>&amp; dims = x.<a class="code hl_function" href="classTensor.html#a54a0edc085929b2b462574a6a80892b0">dims</a>();</div>
<div class="line"><a id="l00752" name="l00752"></a><span class="lineno">  752</span>    <span class="keywordtype">size_t</span> seq_len = dims[2]; <span class="comment">// Third dimension is sequence length</span></div>
<div class="line"><a id="l00753" name="l00753"></a><span class="lineno">  753</span> </div>
<div class="line"><a id="l00754" name="l00754"></a><span class="lineno">  754</span>    <span class="comment">// Output should have shape (batch_size * seq_len, hidden_size)</span></div>
<div class="line"><a id="l00755" name="l00755"></a><span class="lineno">  755</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> reshaped(batch_size * seq_len, <a class="code hl_variable" href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">hidden_size</a>);</div>
<div class="line"><a id="l00756" name="l00756"></a><span class="lineno">  756</span> </div>
<div class="line"><a id="l00757" name="l00757"></a><span class="lineno">  757</span>    <span class="comment">// Reshape from [batch_size, num_heads, seq_len, head_dim] to [batch_size * seq_len,</span></div>
<div class="line"><a id="l00758" name="l00758"></a><span class="lineno">  758</span>    <span class="comment">// hidden_size]</span></div>
<div class="line"><a id="l00759" name="l00759"></a><span class="lineno">  759</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> b = 0; b &lt; batch_size; ++b) {</div>
<div class="line"><a id="l00760" name="l00760"></a><span class="lineno">  760</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> s = 0; s &lt; seq_len; ++s) {</div>
<div class="line"><a id="l00761" name="l00761"></a><span class="lineno">  761</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> h = 0; h &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>; ++h) {</div>
<div class="line"><a id="l00762" name="l00762"></a><span class="lineno">  762</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>; ++d) {</div>
<div class="line"><a id="l00763" name="l00763"></a><span class="lineno">  763</span>                    <span class="comment">// Calculate output position</span></div>
<div class="line"><a id="l00764" name="l00764"></a><span class="lineno">  764</span>                    <span class="keywordtype">size_t</span> out_row = b * seq_len + s;</div>
<div class="line"><a id="l00765" name="l00765"></a><span class="lineno">  765</span>                    <span class="keywordtype">size_t</span> out_col = h * <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> + d;</div>
<div class="line"><a id="l00766" name="l00766"></a><span class="lineno">  766</span> </div>
<div class="line"><a id="l00767" name="l00767"></a><span class="lineno">  767</span>                    <span class="comment">// Get value from tensor</span></div>
<div class="line"><a id="l00768" name="l00768"></a><span class="lineno">  768</span>                    reshaped(out_row, out_col) = x.<a class="code hl_function" href="classTensor.html#a5660c81a5a0ff70a748f818c07010c87">at</a>(b, h, s, d);</div>
<div class="line"><a id="l00769" name="l00769"></a><span class="lineno">  769</span>                }</div>
<div class="line"><a id="l00770" name="l00770"></a><span class="lineno">  770</span>            }</div>
<div class="line"><a id="l00771" name="l00771"></a><span class="lineno">  771</span>        }</div>
<div class="line"><a id="l00772" name="l00772"></a><span class="lineno">  772</span>    }</div>
<div class="line"><a id="l00773" name="l00773"></a><span class="lineno">  773</span> </div>
<div class="line"><a id="l00774" name="l00774"></a><span class="lineno">  774</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Reshaped output dimensions: &quot;</span> &lt;&lt; reshaped.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; reshaped.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>()</div>
<div class="line"><a id="l00775" name="l00775"></a><span class="lineno">  775</span>              &lt;&lt; std::endl;</div>
<div class="line"><a id="l00776" name="l00776"></a><span class="lineno">  776</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;=== reshape_from_attention END ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00777" name="l00777"></a><span class="lineno">  777</span> </div>
<div class="line"><a id="l00778" name="l00778"></a><span class="lineno">  778</span>    <span class="keywordflow">return</span> reshaped;</div>
<div class="line"><a id="l00779" name="l00779"></a><span class="lineno">  779</span>}</div>
</div>
<div class="line"><a id="l00780" name="l00780"></a><span class="lineno">  780</span> </div>
<div class="foldopen" id="foldopen00781" data-start="{" data-end="}">
<div class="line"><a id="l00781" name="l00781"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#ab19f508223deaa017a7f924f0946d25a">  781</a></span><a class="code hl_class" href="classMatrix.html">Matrix</a> <a class="code hl_function" href="classMultiHeadAttention.html#a0df29ad720ff58e8ffd73d3fcb2e6b26">MultiHeadAttention::compute_attention</a>(<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; Q, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; K, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; V,</div>
<div class="line"><a id="l00782" name="l00782"></a><span class="lineno">  782</span>                                             <span class="keyword">const</span> <a class="code hl_class" href="classAttentionMask.html">AttentionMask</a>&amp; mask) {</div>
<div class="line"><a id="l00783" name="l00783"></a><span class="lineno">  783</span>    <span class="comment">// Validate input dimensions</span></div>
<div class="line"><a id="l00784" name="l00784"></a><span class="lineno">  784</span>    <span class="keywordflow">if</span> (Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() != K.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() || K.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() != V.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>()) {</div>
<div class="line"><a id="l00785" name="l00785"></a><span class="lineno">  785</span>        <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;Q, K, V dimension mismatch&quot;</span>);</div>
<div class="line"><a id="l00786" name="l00786"></a><span class="lineno">  786</span>    }</div>
<div class="line"><a id="l00787" name="l00787"></a><span class="lineno">  787</span> </div>
<div class="line"><a id="l00788" name="l00788"></a><span class="lineno">  788</span>    <span class="keywordtype">size_t</span> seq_len = Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>();</div>
<div class="line"><a id="l00789" name="l00789"></a><span class="lineno">  789</span>    <span class="keywordtype">size_t</span> head_size = Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() / <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>;</div>
<div class="line"><a id="l00790" name="l00790"></a><span class="lineno">  790</span> </div>
<div class="line"><a id="l00791" name="l00791"></a><span class="lineno">  791</span>    <span class="comment">// Debug dimensions</span></div>
<div class="line"><a id="l00792" name="l00792"></a><span class="lineno">  792</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Attention dimensions:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00793" name="l00793"></a><span class="lineno">  793</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Q: &quot;</span> &lt;&lt; Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00794" name="l00794"></a><span class="lineno">  794</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;K: &quot;</span> &lt;&lt; K.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; K.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00795" name="l00795"></a><span class="lineno">  795</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;V: &quot;</span> &lt;&lt; V.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; V.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00796" name="l00796"></a><span class="lineno">  796</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;seq_len: &quot;</span> &lt;&lt; seq_len &lt;&lt; <span class="stringliteral">&quot;, head_size: &quot;</span> &lt;&lt; head_size</div>
<div class="line"><a id="l00797" name="l00797"></a><span class="lineno">  797</span>              &lt;&lt; <span class="stringliteral">&quot;, num_heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00798" name="l00798"></a><span class="lineno">  798</span> </div>
<div class="line"><a id="l00799" name="l00799"></a><span class="lineno">  799</span>    <span class="comment">// Reshape maintaining [seq_len, hidden_size] as the basic shape</span></div>
<div class="line"><a id="l00800" name="l00800"></a><span class="lineno">  800</span>    <a class="code hl_class" href="classTensor.html">Tensor</a> Q_reshaped = <a class="code hl_function" href="classMultiHeadAttention.html#ad58475dba6a9acf0f788a069807ca678">reshape_for_attention</a>(Q, 1, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, seq_len, head_size);</div>
<div class="line"><a id="l00801" name="l00801"></a><span class="lineno">  801</span>    <a class="code hl_class" href="classTensor.html">Tensor</a> K_reshaped = <a class="code hl_function" href="classMultiHeadAttention.html#ad58475dba6a9acf0f788a069807ca678">reshape_for_attention</a>(K, 1, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, seq_len, head_size);</div>
<div class="line"><a id="l00802" name="l00802"></a><span class="lineno">  802</span>    <a class="code hl_class" href="classTensor.html">Tensor</a> V_reshaped = <a class="code hl_function" href="classMultiHeadAttention.html#ad58475dba6a9acf0f788a069807ca678">reshape_for_attention</a>(V, 1, <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>, seq_len, head_size);</div>
<div class="line"><a id="l00803" name="l00803"></a><span class="lineno">  803</span> </div>
<div class="line"><a id="l00804" name="l00804"></a><span class="lineno">  804</span>    <span class="comment">// Convert to matrices for computation while preserving effective dimensions</span></div>
<div class="line"><a id="l00805" name="l00805"></a><span class="lineno">  805</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> Q_mat = Q_reshaped.<a class="code hl_function" href="classTensor.html#a9a5d2151ffda672db158dd7167a5ae5b">to_matrix</a>(); <span class="comment">// [num_heads * seq_len, head_size]</span></div>
<div class="line"><a id="l00806" name="l00806"></a><span class="lineno">  806</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> K_mat = K_reshaped.<a class="code hl_function" href="classTensor.html#a9a5d2151ffda672db158dd7167a5ae5b">to_matrix</a>(); <span class="comment">// [num_heads * seq_len, head_size]</span></div>
<div class="line"><a id="l00807" name="l00807"></a><span class="lineno">  807</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> V_mat = V_reshaped.<a class="code hl_function" href="classTensor.html#a9a5d2151ffda672db158dd7167a5ae5b">to_matrix</a>(); <span class="comment">// [num_heads * seq_len, head_size]</span></div>
<div class="line"><a id="l00808" name="l00808"></a><span class="lineno">  808</span> </div>
<div class="line"><a id="l00809" name="l00809"></a><span class="lineno">  809</span>    <span class="comment">// Compute attention scores</span></div>
<div class="line"><a id="l00810" name="l00810"></a><span class="lineno">  810</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> scores = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(Q_mat, K_mat.<a class="code hl_function" href="classMatrix.html#a759661b75b9681f3a89ff75e27933b3a">transpose</a>()); <span class="comment">// [num_heads * seq_len, seq_len]</span></div>
<div class="line"><a id="l00811" name="l00811"></a><span class="lineno">  811</span> </div>
<div class="line"><a id="l00812" name="l00812"></a><span class="lineno">  812</span>    <span class="comment">// Scale scores</span></div>
<div class="line"><a id="l00813" name="l00813"></a><span class="lineno">  813</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> scale = 1.0f / std::sqrt(<span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(head_size));</div>
<div class="line"><a id="l00814" name="l00814"></a><span class="lineno">  814</span>    scores *= scale;</div>
<div class="line"><a id="l00815" name="l00815"></a><span class="lineno">  815</span> </div>
<div class="line"><a id="l00816" name="l00816"></a><span class="lineno">  816</span>    <span class="keywordflow">if</span> (!mask.<a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>.<a class="code hl_function" href="classMatrix.html#a6efb67c1b998ea7ffdc0a1e1b4252e62">empty</a>()) {</div>
<div class="line"><a id="l00817" name="l00817"></a><span class="lineno">  817</span>        <span class="comment">// Create expanded mask for all attention heads</span></div>
<div class="line"><a id="l00818" name="l00818"></a><span class="lineno">  818</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> expanded_mask(scores.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(), scores.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(), 1.0f);</div>
<div class="line"><a id="l00819" name="l00819"></a><span class="lineno">  819</span> </div>
<div class="line"><a id="l00820" name="l00820"></a><span class="lineno">  820</span>        <span class="comment">// Repeat the mask for each attention head</span></div>
<div class="line"><a id="l00821" name="l00821"></a><span class="lineno">  821</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> h = 0; h &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>; ++h) {</div>
<div class="line"><a id="l00822" name="l00822"></a><span class="lineno">  822</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; seq_len; ++i) {</div>
<div class="line"><a id="l00823" name="l00823"></a><span class="lineno">  823</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; seq_len; ++j) {</div>
<div class="line"><a id="l00824" name="l00824"></a><span class="lineno">  824</span>                    expanded_mask(h * seq_len + i, h * seq_len + j) = mask.<a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>(i, j);</div>
<div class="line"><a id="l00825" name="l00825"></a><span class="lineno">  825</span>                }</div>
<div class="line"><a id="l00826" name="l00826"></a><span class="lineno">  826</span>            }</div>
<div class="line"><a id="l00827" name="l00827"></a><span class="lineno">  827</span>        }</div>
<div class="line"><a id="l00828" name="l00828"></a><span class="lineno">  828</span> </div>
<div class="line"><a id="l00829" name="l00829"></a><span class="lineno">  829</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Original mask shape: &quot;</span> &lt;&lt; mask.<a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; mask.<a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>()</div>
<div class="line"><a id="l00830" name="l00830"></a><span class="lineno">  830</span>                  &lt;&lt; std::endl;</div>
<div class="line"><a id="l00831" name="l00831"></a><span class="lineno">  831</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Expanded mask shape: &quot;</span> &lt;&lt; expanded_mask.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; expanded_mask.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>()</div>
<div class="line"><a id="l00832" name="l00832"></a><span class="lineno">  832</span>                  &lt;&lt; std::endl;</div>
<div class="line"><a id="l00833" name="l00833"></a><span class="lineno">  833</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Scores shape: &quot;</span> &lt;&lt; scores.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; scores.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00834" name="l00834"></a><span class="lineno">  834</span> </div>
<div class="line"><a id="l00835" name="l00835"></a><span class="lineno">  835</span>        <a class="code hl_function" href="classMultiHeadAttention.html#a3ccbdfe184867bfb5ba90cd103bd2eb0">apply_mask</a>(scores, expanded_mask);</div>
<div class="line"><a id="l00836" name="l00836"></a><span class="lineno">  836</span>    }</div>
<div class="line"><a id="l00837" name="l00837"></a><span class="lineno">  837</span> </div>
<div class="line"><a id="l00838" name="l00838"></a><span class="lineno">  838</span>    <a class="code hl_function" href="classMultiHeadAttention.html#a666bd13dfa5833931c2b3176ebf3d2f8">apply_stable_softmax</a>(scores);</div>
<div class="line"><a id="l00839" name="l00839"></a><span class="lineno">  839</span> </div>
<div class="line"><a id="l00840" name="l00840"></a><span class="lineno">  840</span>    <span class="comment">// Compute attention output</span></div>
<div class="line"><a id="l00841" name="l00841"></a><span class="lineno">  841</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> attention = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(scores, V_mat); <span class="comment">// [num_heads * seq_len, head_size]</span></div>
<div class="line"><a id="l00842" name="l00842"></a><span class="lineno">  842</span> </div>
<div class="line"><a id="l00843" name="l00843"></a><span class="lineno">  843</span>    <span class="comment">// Reshape back to [seq_len, hidden_size]</span></div>
<div class="line"><a id="l00844" name="l00844"></a><span class="lineno">  844</span>    std::vector&lt;unsigned long&gt; dims = {</div>
<div class="line"><a id="l00845" name="l00845"></a><span class="lineno">  845</span>        <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">long</span><span class="keyword">&gt;</span>(1), <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">long</span><span class="keyword">&gt;</span>(<a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>),</div>
<div class="line"><a id="l00846" name="l00846"></a><span class="lineno">  846</span>        <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">long</span><span class="keyword">&gt;</span>(seq_len), <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">long</span><span class="keyword">&gt;</span>(head_size)};</div>
<div class="line"><a id="l00847" name="l00847"></a><span class="lineno">  847</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="classMultiHeadAttention.html#aff569533c7e7f11a7fa4b6ba1662efc5">reshape_from_attention</a>(<a class="code hl_class" href="classTensor.html">Tensor</a>(attention, dims), seq_len, <a class="code hl_variable" href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">hidden_size</a>);</div>
<div class="line"><a id="l00848" name="l00848"></a><span class="lineno">  848</span>}</div>
</div>
<div class="line"><a id="l00849" name="l00849"></a><span class="lineno">  849</span> </div>
<div class="foldopen" id="foldopen00850" data-start="{" data-end="}">
<div class="line"><a id="l00850" name="l00850"></a><span class="lineno"><a class="line" href="classAttentionMask.html#a12b920e427facb6c1152fb7463291287">  850</a></span><a class="code hl_class" href="classAttentionMask.html">AttentionMask</a> <a class="code hl_function" href="classAttentionMask.html#a12b920e427facb6c1152fb7463291287">AttentionMask::create_causal_mask</a>(<span class="keywordtype">size_t</span> size) {</div>
<div class="line"><a id="l00851" name="l00851"></a><span class="lineno">  851</span>    <a class="code hl_class" href="classAttentionMask.html">AttentionMask</a> <a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>;</div>
<div class="line"><a id="l00852" name="l00852"></a><span class="lineno">  852</span>    <a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>.mask = <a class="code hl_class" href="classMatrix.html">Matrix</a>(size, size, 0.0f);</div>
<div class="line"><a id="l00853" name="l00853"></a><span class="lineno">  853</span> </div>
<div class="line"><a id="l00854" name="l00854"></a><span class="lineno">  854</span>    <span class="comment">// Create lower triangular matrix</span></div>
<div class="line"><a id="l00855" name="l00855"></a><span class="lineno">  855</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; size; ++i) {</div>
<div class="line"><a id="l00856" name="l00856"></a><span class="lineno">  856</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; size &amp;&amp; j &lt;= i; ++j) {</div>
<div class="line"><a id="l00857" name="l00857"></a><span class="lineno">  857</span>            <a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>.mask(<span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">long</span><span class="keyword">&gt;</span>(i), <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">long</span><span class="keyword">&gt;</span>(j)) = 1.0f;</div>
<div class="line"><a id="l00858" name="l00858"></a><span class="lineno">  858</span>        }</div>
<div class="line"><a id="l00859" name="l00859"></a><span class="lineno">  859</span>    }</div>
<div class="line"><a id="l00860" name="l00860"></a><span class="lineno">  860</span>    <span class="keywordflow">return</span> <a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>;</div>
<div class="line"><a id="l00861" name="l00861"></a><span class="lineno">  861</span>}</div>
</div>
<div class="line"><a id="l00862" name="l00862"></a><span class="lineno">  862</span> </div>
<div class="foldopen" id="foldopen00863" data-start="{" data-end="}">
<div class="line"><a id="l00863" name="l00863"></a><span class="lineno"><a class="line" href="classAttentionMask.html#a75f94e4bb34636e221d76c1bbad8bc5a">  863</a></span><a class="code hl_class" href="classAttentionMask.html">AttentionMask</a> <a class="code hl_function" href="classAttentionMask.html#a75f94e4bb34636e221d76c1bbad8bc5a">AttentionMask::create_padding_mask</a>(<span class="keyword">const</span> std::vector&lt;int&gt;&amp; lengths, <span class="keywordtype">size_t</span> max_len) {</div>
<div class="line"><a id="l00864" name="l00864"></a><span class="lineno">  864</span>    <a class="code hl_class" href="classAttentionMask.html">AttentionMask</a> <a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>;</div>
<div class="line"><a id="l00865" name="l00865"></a><span class="lineno">  865</span>    <span class="keywordtype">size_t</span> batch_size = lengths.<a class="code hl_function" href="classMatrix.html#aeb6be0338f7e26667962470f4766120b">size</a>();</div>
<div class="line"><a id="l00866" name="l00866"></a><span class="lineno">  866</span>    <a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>.mask = <a class="code hl_class" href="classMatrix.html">Matrix</a>(max_len, max_len, 0.0f);</div>
<div class="line"><a id="l00867" name="l00867"></a><span class="lineno">  867</span> </div>
<div class="line"><a id="l00868" name="l00868"></a><span class="lineno">  868</span>    <span class="comment">// Create padding mask</span></div>
<div class="line"><a id="l00869" name="l00869"></a><span class="lineno">  869</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; max_len; ++i) {</div>
<div class="line"><a id="l00870" name="l00870"></a><span class="lineno">  870</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; max_len; ++j) {</div>
<div class="line"><a id="l00871" name="l00871"></a><span class="lineno">  871</span>            <span class="comment">// Allow attention up to the sequence length</span></div>
<div class="line"><a id="l00872" name="l00872"></a><span class="lineno">  872</span>            <a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>.mask(i, j) = (i &lt; lengths[0] &amp;&amp; j &lt; lengths[0]) ? 1.0f : 0.0f;</div>
<div class="line"><a id="l00873" name="l00873"></a><span class="lineno">  873</span>        }</div>
<div class="line"><a id="l00874" name="l00874"></a><span class="lineno">  874</span>    }</div>
<div class="line"><a id="l00875" name="l00875"></a><span class="lineno">  875</span>    <span class="keywordflow">return</span> <a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>;</div>
<div class="line"><a id="l00876" name="l00876"></a><span class="lineno">  876</span>}</div>
</div>
<div class="line"><a id="l00877" name="l00877"></a><span class="lineno">  877</span> </div>
<div class="foldopen" id="foldopen00878" data-start="{" data-end="}">
<div class="line"><a id="l00878" name="l00878"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#a0df29ad720ff58e8ffd73d3fcb2e6b26">  878</a></span><a class="code hl_class" href="classTensor.html">Tensor</a> <a class="code hl_function" href="classMultiHeadAttention.html#a0df29ad720ff58e8ffd73d3fcb2e6b26">MultiHeadAttention::compute_attention</a>(<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; Q, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; K, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; V,</div>
<div class="line"><a id="l00879" name="l00879"></a><span class="lineno">  879</span>                                             <span class="keyword">const</span> <a class="code hl_class" href="classAttentionMask.html">AttentionMask</a>&amp; mask, <span class="keywordtype">size_t</span> batch_size,</div>
<div class="line"><a id="l00880" name="l00880"></a><span class="lineno">  880</span>                                             <span class="keywordtype">size_t</span> num_heads, <span class="keywordtype">size_t</span> seq_len, <span class="keywordtype">size_t</span> head_dim) {</div>
<div class="line"><a id="l00881" name="l00881"></a><span class="lineno">  881</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;=== compute_attention START ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00882" name="l00882"></a><span class="lineno">  882</span> </div>
<div class="line"><a id="l00883" name="l00883"></a><span class="lineno">  883</span>    <span class="comment">// Validate input dimensions</span></div>
<div class="line"><a id="l00884" name="l00884"></a><span class="lineno">  884</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Validating dimensions...&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00885" name="l00885"></a><span class="lineno">  885</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Expected dimensions:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00886" name="l00886"></a><span class="lineno">  886</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- batch_size: &quot;</span> &lt;&lt; batch_size &lt;&lt; std::endl;</div>
<div class="line"><a id="l00887" name="l00887"></a><span class="lineno">  887</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- num_heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00888" name="l00888"></a><span class="lineno">  888</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- seq_len: &quot;</span> &lt;&lt; seq_len &lt;&lt; std::endl;</div>
<div class="line"><a id="l00889" name="l00889"></a><span class="lineno">  889</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- head_dim: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00890" name="l00890"></a><span class="lineno">  890</span> </div>
<div class="line"><a id="l00891" name="l00891"></a><span class="lineno">  891</span>    <span class="keywordtype">size_t</span> expected_rows = batch_size * <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> * seq_len;</div>
<div class="line"><a id="l00892" name="l00892"></a><span class="lineno">  892</span>    <span class="keywordtype">size_t</span> expected_cols = <a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>;</div>
<div class="line"><a id="l00893" name="l00893"></a><span class="lineno">  893</span> </div>
<div class="line"><a id="l00894" name="l00894"></a><span class="lineno">  894</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Q dimensions: &quot;</span> &lt;&lt; Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00895" name="l00895"></a><span class="lineno">  895</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;K dimensions: &quot;</span> &lt;&lt; K.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; K.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00896" name="l00896"></a><span class="lineno">  896</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;V dimensions: &quot;</span> &lt;&lt; V.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; V.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l00897" name="l00897"></a><span class="lineno">  897</span> </div>
<div class="line"><a id="l00898" name="l00898"></a><span class="lineno">  898</span>    <span class="comment">// Dimension validation...</span></div>
<div class="line"><a id="l00899" name="l00899"></a><span class="lineno">  899</span>    <span class="keywordflow">if</span> (Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() != expected_rows || Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() != expected_cols) {</div>
<div class="line"><a id="l00900" name="l00900"></a><span class="lineno">  900</span>        <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;Q dimensions mismatch&quot;</span>);</div>
<div class="line"><a id="l00901" name="l00901"></a><span class="lineno">  901</span>    }</div>
<div class="line"><a id="l00902" name="l00902"></a><span class="lineno">  902</span>    <span class="keywordflow">if</span> (K.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() != expected_rows || K.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() != expected_cols) {</div>
<div class="line"><a id="l00903" name="l00903"></a><span class="lineno">  903</span>        <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;K dimensions mismatch&quot;</span>);</div>
<div class="line"><a id="l00904" name="l00904"></a><span class="lineno">  904</span>    }</div>
<div class="line"><a id="l00905" name="l00905"></a><span class="lineno">  905</span>    <span class="keywordflow">if</span> (V.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() != expected_rows || V.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() != expected_cols) {</div>
<div class="line"><a id="l00906" name="l00906"></a><span class="lineno">  906</span>        <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;V dimensions mismatch&quot;</span>);</div>
<div class="line"><a id="l00907" name="l00907"></a><span class="lineno">  907</span>    }</div>
<div class="line"><a id="l00908" name="l00908"></a><span class="lineno">  908</span> </div>
<div class="line"><a id="l00909" name="l00909"></a><span class="lineno">  909</span>    <span class="comment">// Initialize output matrix</span></div>
<div class="line"><a id="l00910" name="l00910"></a><span class="lineno">  910</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> output(Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(), V.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(), 0.0f);</div>
<div class="line"><a id="l00911" name="l00911"></a><span class="lineno">  911</span> </div>
<div class="line"><a id="l00912" name="l00912"></a><span class="lineno">  912</span>    <span class="comment">// Block size for processing (adjust based on available memory)</span></div>
<div class="line"><a id="l00913" name="l00913"></a><span class="lineno">  913</span>    <span class="keyword">const</span> <span class="keywordtype">size_t</span> BLOCK_SIZE = 1024; <span class="comment">// Process 1024 rows at a time</span></div>
<div class="line"><a id="l00914" name="l00914"></a><span class="lineno">  914</span>    <span class="keywordtype">float</span> scale_factor = 1.0f / std::sqrt(<span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(<a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>));</div>
<div class="line"><a id="l00915" name="l00915"></a><span class="lineno">  915</span> </div>
<div class="line"><a id="l00916" name="l00916"></a><span class="lineno">  916</span>    <span class="comment">// Process attention in blocks</span></div>
<div class="line"><a id="l00917" name="l00917"></a><span class="lineno">  917</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> start_idx = 0; start_idx &lt; Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(); start_idx += BLOCK_SIZE) {</div>
<div class="line"><a id="l00918" name="l00918"></a><span class="lineno">  918</span>        <span class="keywordtype">size_t</span> end_idx = std::min(start_idx + BLOCK_SIZE, Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>());</div>
<div class="line"><a id="l00919" name="l00919"></a><span class="lineno">  919</span>        <span class="keywordtype">size_t</span> current_block_size = end_idx - start_idx;</div>
<div class="line"><a id="l00920" name="l00920"></a><span class="lineno">  920</span> </div>
<div class="line"><a id="l00921" name="l00921"></a><span class="lineno">  921</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Processing block &quot;</span> &lt;&lt; start_idx / BLOCK_SIZE + 1 &lt;&lt; <span class="stringliteral">&quot; of &quot;</span></div>
<div class="line"><a id="l00922" name="l00922"></a><span class="lineno">  922</span>                  &lt;&lt; (Q.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() + BLOCK_SIZE - 1) / BLOCK_SIZE &lt;&lt; std::endl;</div>
<div class="line"><a id="l00923" name="l00923"></a><span class="lineno">  923</span> </div>
<div class="line"><a id="l00924" name="l00924"></a><span class="lineno">  924</span>        <span class="comment">// Extract block of Q</span></div>
<div class="line"><a id="l00925" name="l00925"></a><span class="lineno">  925</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> Q_block(current_block_size, Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>());</div>
<div class="line"><a id="l00926" name="l00926"></a><span class="lineno">  926</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; current_block_size; ++i) {</div>
<div class="line"><a id="l00927" name="l00927"></a><span class="lineno">  927</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; Q.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); ++j) {</div>
<div class="line"><a id="l00928" name="l00928"></a><span class="lineno">  928</span>                Q_block(i, j) = Q(start_idx + i, j);</div>
<div class="line"><a id="l00929" name="l00929"></a><span class="lineno">  929</span>            }</div>
<div class="line"><a id="l00930" name="l00930"></a><span class="lineno">  930</span>        }</div>
<div class="line"><a id="l00931" name="l00931"></a><span class="lineno">  931</span> </div>
<div class="line"><a id="l00932" name="l00932"></a><span class="lineno">  932</span>        <span class="comment">// Compute scores for this block</span></div>
<div class="line"><a id="l00933" name="l00933"></a><span class="lineno">  933</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> scores = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(Q_block, K.<a class="code hl_function" href="classMatrix.html#a759661b75b9681f3a89ff75e27933b3a">transpose</a>());</div>
<div class="line"><a id="l00934" name="l00934"></a><span class="lineno">  934</span>        scores *= scale_factor;</div>
<div class="line"><a id="l00935" name="l00935"></a><span class="lineno">  935</span> </div>
<div class="line"><a id="l00936" name="l00936"></a><span class="lineno">  936</span>        <span class="comment">// Apply mask for this block if provided</span></div>
<div class="line"><a id="l00937" name="l00937"></a><span class="lineno">  937</span>        <span class="keywordflow">if</span> (!mask.<a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>.<a class="code hl_function" href="classMatrix.html#a6efb67c1b998ea7ffdc0a1e1b4252e62">empty</a>()) {</div>
<div class="line"><a id="l00938" name="l00938"></a><span class="lineno">  938</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; current_block_size; ++i) {</div>
<div class="line"><a id="l00939" name="l00939"></a><span class="lineno">  939</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; K.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(); ++j) {</div>
<div class="line"><a id="l00940" name="l00940"></a><span class="lineno">  940</span>                    <span class="comment">// Calculate original indices for masking</span></div>
<div class="line"><a id="l00941" name="l00941"></a><span class="lineno">  941</span>                    <span class="keywordtype">size_t</span> orig_i = start_idx + i;</div>
<div class="line"><a id="l00942" name="l00942"></a><span class="lineno">  942</span>                    <span class="keywordtype">size_t</span> batch_idx_i = orig_i / (<a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> * seq_len);</div>
<div class="line"><a id="l00943" name="l00943"></a><span class="lineno">  943</span>                    <span class="keywordtype">size_t</span> head_idx_i = (orig_i % (<a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> * seq_len)) / seq_len;</div>
<div class="line"><a id="l00944" name="l00944"></a><span class="lineno">  944</span>                    <span class="keywordtype">size_t</span> seq_idx_i = orig_i % seq_len;</div>
<div class="line"><a id="l00945" name="l00945"></a><span class="lineno">  945</span> </div>
<div class="line"><a id="l00946" name="l00946"></a><span class="lineno">  946</span>                    <span class="keywordtype">size_t</span> batch_idx_j = j / (<a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> * seq_len);</div>
<div class="line"><a id="l00947" name="l00947"></a><span class="lineno">  947</span>                    <span class="keywordtype">size_t</span> head_idx_j = (j % (<a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> * seq_len)) / seq_len;</div>
<div class="line"><a id="l00948" name="l00948"></a><span class="lineno">  948</span>                    <span class="keywordtype">size_t</span> seq_idx_j = j % seq_len;</div>
<div class="line"><a id="l00949" name="l00949"></a><span class="lineno">  949</span> </div>
<div class="line"><a id="l00950" name="l00950"></a><span class="lineno">  950</span>                    <span class="comment">// Apply mask only within same batch and head</span></div>
<div class="line"><a id="l00951" name="l00951"></a><span class="lineno">  951</span>                    <span class="keywordflow">if</span> (batch_idx_i == batch_idx_j &amp;&amp; head_idx_i == head_idx_j) {</div>
<div class="line"><a id="l00952" name="l00952"></a><span class="lineno">  952</span>                        <span class="keywordflow">if</span> (mask.<a class="code hl_variable" href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">mask</a>(seq_idx_i, seq_idx_j) == 0.0f) {</div>
<div class="line"><a id="l00953" name="l00953"></a><span class="lineno">  953</span>                            scores(i, j) = -std::numeric_limits&lt;float&gt;::infinity();</div>
<div class="line"><a id="l00954" name="l00954"></a><span class="lineno">  954</span>                        }</div>
<div class="line"><a id="l00955" name="l00955"></a><span class="lineno">  955</span>                    }</div>
<div class="line"><a id="l00956" name="l00956"></a><span class="lineno">  956</span>                }</div>
<div class="line"><a id="l00957" name="l00957"></a><span class="lineno">  957</span>            }</div>
<div class="line"><a id="l00958" name="l00958"></a><span class="lineno">  958</span>        }</div>
<div class="line"><a id="l00959" name="l00959"></a><span class="lineno">  959</span> </div>
<div class="line"><a id="l00960" name="l00960"></a><span class="lineno">  960</span>        <span class="comment">// Apply softmax row-wise</span></div>
<div class="line"><a id="l00961" name="l00961"></a><span class="lineno">  961</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; current_block_size; ++i) {</div>
<div class="line"><a id="l00962" name="l00962"></a><span class="lineno">  962</span>            <span class="keywordtype">float</span> max_val = -std::numeric_limits&lt;float&gt;::infinity();</div>
<div class="line"><a id="l00963" name="l00963"></a><span class="lineno">  963</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; scores.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); ++j) {</div>
<div class="line"><a id="l00964" name="l00964"></a><span class="lineno">  964</span>                max_val = std::max(max_val, scores(i, j));</div>
<div class="line"><a id="l00965" name="l00965"></a><span class="lineno">  965</span>            }</div>
<div class="line"><a id="l00966" name="l00966"></a><span class="lineno">  966</span> </div>
<div class="line"><a id="l00967" name="l00967"></a><span class="lineno">  967</span>            <span class="keywordtype">float</span> sum = 0.0f;</div>
<div class="line"><a id="l00968" name="l00968"></a><span class="lineno">  968</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; scores.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); ++j) {</div>
<div class="line"><a id="l00969" name="l00969"></a><span class="lineno">  969</span>                scores(i, j) = std::exp(scores(i, j) - max_val);</div>
<div class="line"><a id="l00970" name="l00970"></a><span class="lineno">  970</span>                sum += scores(i, j);</div>
<div class="line"><a id="l00971" name="l00971"></a><span class="lineno">  971</span>            }</div>
<div class="line"><a id="l00972" name="l00972"></a><span class="lineno">  972</span> </div>
<div class="line"><a id="l00973" name="l00973"></a><span class="lineno">  973</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; scores.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); ++j) {</div>
<div class="line"><a id="l00974" name="l00974"></a><span class="lineno">  974</span>                scores(i, j) /= sum;</div>
<div class="line"><a id="l00975" name="l00975"></a><span class="lineno">  975</span>            }</div>
<div class="line"><a id="l00976" name="l00976"></a><span class="lineno">  976</span>        }</div>
<div class="line"><a id="l00977" name="l00977"></a><span class="lineno">  977</span> </div>
<div class="line"><a id="l00978" name="l00978"></a><span class="lineno">  978</span>        <span class="comment">// Compute output for this block</span></div>
<div class="line"><a id="l00979" name="l00979"></a><span class="lineno">  979</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a> block_output = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(scores, V);</div>
<div class="line"><a id="l00980" name="l00980"></a><span class="lineno">  980</span> </div>
<div class="line"><a id="l00981" name="l00981"></a><span class="lineno">  981</span>        <span class="comment">// Add block output to final output</span></div>
<div class="line"><a id="l00982" name="l00982"></a><span class="lineno">  982</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; current_block_size; ++i) {</div>
<div class="line"><a id="l00983" name="l00983"></a><span class="lineno">  983</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; V.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); ++j) {</div>
<div class="line"><a id="l00984" name="l00984"></a><span class="lineno">  984</span>                output(start_idx + i, j) = block_output(i, j);</div>
<div class="line"><a id="l00985" name="l00985"></a><span class="lineno">  985</span>            }</div>
<div class="line"><a id="l00986" name="l00986"></a><span class="lineno">  986</span>        }</div>
<div class="line"><a id="l00987" name="l00987"></a><span class="lineno">  987</span>    }</div>
<div class="line"><a id="l00988" name="l00988"></a><span class="lineno">  988</span> </div>
<div class="line"><a id="l00989" name="l00989"></a><span class="lineno">  989</span>    <span class="comment">// Create tensor with proper dimensions</span></div>
<div class="line"><a id="l00990" name="l00990"></a><span class="lineno">  990</span>    std::vector&lt;unsigned long&gt; dims = {</div>
<div class="line"><a id="l00991" name="l00991"></a><span class="lineno">  991</span>        <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">long</span><span class="keyword">&gt;</span>(batch_size), <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">long</span><span class="keyword">&gt;</span>(<a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>),</div>
<div class="line"><a id="l00992" name="l00992"></a><span class="lineno">  992</span>        <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">long</span><span class="keyword">&gt;</span>(seq_len), <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">long</span><span class="keyword">&gt;</span>(<a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>)};</div>
<div class="line"><a id="l00993" name="l00993"></a><span class="lineno">  993</span> </div>
<div class="line"><a id="l00994" name="l00994"></a><span class="lineno">  994</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;=== compute_attention END ===&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00995" name="l00995"></a><span class="lineno">  995</span>    <span class="keywordflow">return</span> <a class="code hl_class" href="classTensor.html">Tensor</a>(output, dims);</div>
<div class="line"><a id="l00996" name="l00996"></a><span class="lineno">  996</span>}</div>
</div>
<div class="line"><a id="l00997" name="l00997"></a><span class="lineno">  997</span> </div>
<div class="foldopen" id="foldopen00998" data-start="{" data-end="}">
<div class="line"><a id="l00998" name="l00998"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#a6cc7e11046066e5d752d9112c56d16f2">  998</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classMultiHeadAttention.html#a6cc7e11046066e5d752d9112c56d16f2">MultiHeadAttention::initialize_rope_cache</a>(<span class="keywordtype">size_t</span> max_seq_len, <span class="keywordtype">size_t</span> dim) {</div>
<div class="line"><a id="l00999" name="l00999"></a><span class="lineno">  999</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Initializing RoPE cache:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l01000" name="l01000"></a><span class="lineno"> 1000</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- max_seq_len: &quot;</span> &lt;&lt; max_seq_len &lt;&lt; std::endl;</div>
<div class="line"><a id="l01001" name="l01001"></a><span class="lineno"> 1001</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- dim: &quot;</span> &lt;&lt; dim &lt;&lt; std::endl;</div>
<div class="line"><a id="l01002" name="l01002"></a><span class="lineno"> 1002</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- num_heads: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a> &lt;&lt; std::endl;</div>
<div class="line"><a id="l01003" name="l01003"></a><span class="lineno"> 1003</span> </div>
<div class="line"><a id="l01004" name="l01004"></a><span class="lineno"> 1004</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#a5549a32f6e8ee18e5e69d7a56f1365de">cos_cached</a> = <a class="code hl_class" href="classMatrix.html">Matrix</a>(max_seq_len, dim * <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>);</div>
<div class="line"><a id="l01005" name="l01005"></a><span class="lineno"> 1005</span>    <a class="code hl_variable" href="classMultiHeadAttention.html#aef4835723fe043b288a6ac6af6299159">sin_cached</a> = <a class="code hl_class" href="classMatrix.html">Matrix</a>(max_seq_len, dim * <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>);</div>
<div class="line"><a id="l01006" name="l01006"></a><span class="lineno"> 1006</span> </div>
<div class="line"><a id="l01007" name="l01007"></a><span class="lineno"> 1007</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Created cache matrices:&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l01008" name="l01008"></a><span class="lineno"> 1008</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- cos_cached: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a5549a32f6e8ee18e5e69d7a56f1365de">cos_cached</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a5549a32f6e8ee18e5e69d7a56f1365de">cos_cached</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l01009" name="l01009"></a><span class="lineno"> 1009</span>    std::cout &lt;&lt; <span class="stringliteral">&quot;- sin_cached: &quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#aef4835723fe043b288a6ac6af6299159">sin_cached</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; <a class="code hl_variable" href="classMultiHeadAttention.html#aef4835723fe043b288a6ac6af6299159">sin_cached</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() &lt;&lt; std::endl;</div>
<div class="line"><a id="l01010" name="l01010"></a><span class="lineno"> 1010</span> </div>
<div class="line"><a id="l01011" name="l01011"></a><span class="lineno"> 1011</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> pos = 0; pos &lt; max_seq_len; pos++) {</div>
<div class="line"><a id="l01012" name="l01012"></a><span class="lineno"> 1012</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> h = 0; h &lt; <a class="code hl_variable" href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">num_heads</a>; h++) {</div>
<div class="line"><a id="l01013" name="l01013"></a><span class="lineno"> 1013</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; dim; i++) {</div>
<div class="line"><a id="l01014" name="l01014"></a><span class="lineno"> 1014</span>                <span class="keywordtype">size_t</span> idx = h * dim + i;</div>
<div class="line"><a id="l01015" name="l01015"></a><span class="lineno"> 1015</span>                <span class="keywordtype">float</span> theta = std::pow(10000.0f, -2.0f * i / dim);</div>
<div class="line"><a id="l01016" name="l01016"></a><span class="lineno"> 1016</span>                <a class="code hl_variable" href="classMultiHeadAttention.html#a5549a32f6e8ee18e5e69d7a56f1365de">cos_cached</a>(pos, idx) = std::cos(pos * theta);</div>
<div class="line"><a id="l01017" name="l01017"></a><span class="lineno"> 1017</span>                <a class="code hl_variable" href="classMultiHeadAttention.html#aef4835723fe043b288a6ac6af6299159">sin_cached</a>(pos, idx) = std::sin(pos * theta);</div>
<div class="line"><a id="l01018" name="l01018"></a><span class="lineno"> 1018</span>            }</div>
<div class="line"><a id="l01019" name="l01019"></a><span class="lineno"> 1019</span>        }</div>
<div class="line"><a id="l01020" name="l01020"></a><span class="lineno"> 1020</span>    }</div>
<div class="line"><a id="l01021" name="l01021"></a><span class="lineno"> 1021</span>}</div>
</div>
<div class="line"><a id="l01022" name="l01022"></a><span class="lineno"> 1022</span> </div>
<div class="foldopen" id="foldopen01023" data-start="{" data-end="}">
<div class="line"><a id="l01023" name="l01023"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#a02d15d5c760c9461189debefe54dab99"> 1023</a></span><span class="keywordtype">float</span> <a class="code hl_function" href="classMultiHeadAttention.html#a02d15d5c760c9461189debefe54dab99">MultiHeadAttention::get_cos_cached</a>(<span class="keywordtype">size_t</span> pos, <span class="keywordtype">size_t</span> dim_idx)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l01024" name="l01024"></a><span class="lineno"> 1024</span>    <span class="keywordflow">if</span> (pos &gt;= <a class="code hl_variable" href="classMultiHeadAttention.html#a5549a32f6e8ee18e5e69d7a56f1365de">cos_cached</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() || dim_idx &gt;= <a class="code hl_variable" href="classMultiHeadAttention.html#a5549a32f6e8ee18e5e69d7a56f1365de">cos_cached</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>()) {</div>
<div class="line"><a id="l01025" name="l01025"></a><span class="lineno"> 1025</span>        <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;RoPE cache access out of bounds: pos=&quot;</span> + std::to_string(pos) +</div>
<div class="line"><a id="l01026" name="l01026"></a><span class="lineno"> 1026</span>                                 <span class="stringliteral">&quot;, dim=&quot;</span> + std::to_string(dim_idx));</div>
<div class="line"><a id="l01027" name="l01027"></a><span class="lineno"> 1027</span>    }</div>
<div class="line"><a id="l01028" name="l01028"></a><span class="lineno"> 1028</span>    <span class="keywordflow">return</span> <a class="code hl_variable" href="classMultiHeadAttention.html#a5549a32f6e8ee18e5e69d7a56f1365de">cos_cached</a>(pos, dim_idx);</div>
<div class="line"><a id="l01029" name="l01029"></a><span class="lineno"> 1029</span>}</div>
</div>
<div class="line"><a id="l01030" name="l01030"></a><span class="lineno"> 1030</span> </div>
<div class="foldopen" id="foldopen01031" data-start="{" data-end="}">
<div class="line"><a id="l01031" name="l01031"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#ad02e8c0946a244a380de6a145afbce7b"> 1031</a></span><span class="keywordtype">float</span> <a class="code hl_function" href="classMultiHeadAttention.html#ad02e8c0946a244a380de6a145afbce7b">MultiHeadAttention::get_sin_cached</a>(<span class="keywordtype">size_t</span> pos, <span class="keywordtype">size_t</span> dim_idx)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l01032" name="l01032"></a><span class="lineno"> 1032</span>    <span class="keywordflow">if</span> (pos &gt;= <a class="code hl_variable" href="classMultiHeadAttention.html#aef4835723fe043b288a6ac6af6299159">sin_cached</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() || dim_idx &gt;= <a class="code hl_variable" href="classMultiHeadAttention.html#aef4835723fe043b288a6ac6af6299159">sin_cached</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>()) {</div>
<div class="line"><a id="l01033" name="l01033"></a><span class="lineno"> 1033</span>        <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;RoPE cache access out of bounds: pos=&quot;</span> + std::to_string(pos) +</div>
<div class="line"><a id="l01034" name="l01034"></a><span class="lineno"> 1034</span>                                 <span class="stringliteral">&quot;, dim=&quot;</span> + std::to_string(dim_idx));</div>
<div class="line"><a id="l01035" name="l01035"></a><span class="lineno"> 1035</span>    }</div>
<div class="line"><a id="l01036" name="l01036"></a><span class="lineno"> 1036</span>    <span class="keywordflow">return</span> <a class="code hl_variable" href="classMultiHeadAttention.html#aef4835723fe043b288a6ac6af6299159">sin_cached</a>(pos, dim_idx);</div>
<div class="line"><a id="l01037" name="l01037"></a><span class="lineno"> 1037</span>}</div>
</div>
<div class="line"><a id="l01038" name="l01038"></a><span class="lineno"> 1038</span> </div>
<div class="foldopen" id="foldopen01039" data-start="{" data-end="}">
<div class="line"><a id="l01039" name="l01039"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#a36b374cd10b12a404825b10ca5371096"> 1039</a></span><a class="code hl_class" href="classMatrix.html">Matrix</a> <a class="code hl_function" href="classMultiHeadAttention.html#a36b374cd10b12a404825b10ca5371096">MultiHeadAttention::compute_attention_scores</a>(<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; Q, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; K) {</div>
<div class="line"><a id="l01040" name="l01040"></a><span class="lineno"> 1040</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> scores = <a class="code hl_function" href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a>(Q, K.<a class="code hl_function" href="classMatrix.html#a759661b75b9681f3a89ff75e27933b3a">transpose</a>());</div>
<div class="line"><a id="l01041" name="l01041"></a><span class="lineno"> 1041</span> </div>
<div class="line"><a id="l01042" name="l01042"></a><span class="lineno"> 1042</span>    <span class="comment">// Scale scores with careful handling of numerical stability</span></div>
<div class="line"><a id="l01043" name="l01043"></a><span class="lineno"> 1043</span>    <span class="keywordtype">float</span> scale = 1.0f / std::sqrt(<span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(<a class="code hl_variable" href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">head_dim</a>));</div>
<div class="line"><a id="l01044" name="l01044"></a><span class="lineno"> 1044</span> </div>
<div class="line"><a id="l01045" name="l01045"></a><span class="lineno"> 1045</span>    <span class="comment">// Clip extremely large values to prevent overflow</span></div>
<div class="line"><a id="l01046" name="l01046"></a><span class="lineno"> 1046</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> max_score = 100.0f; <span class="comment">// Prevent exp overflow</span></div>
<div class="line"><a id="l01047" name="l01047"></a><span class="lineno"> 1047</span> </div>
<div class="line"><a id="l01048" name="l01048"></a><span class="lineno"> 1048</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; scores.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(); ++i) {</div>
<div class="line"><a id="l01049" name="l01049"></a><span class="lineno"> 1049</span>        <span class="comment">// Find max for numerical stability in softmax</span></div>
<div class="line"><a id="l01050" name="l01050"></a><span class="lineno"> 1050</span>        <span class="keywordtype">float</span> row_max = -std::numeric_limits&lt;float&gt;::infinity();</div>
<div class="line"><a id="l01051" name="l01051"></a><span class="lineno"> 1051</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; scores.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); ++j) {</div>
<div class="line"><a id="l01052" name="l01052"></a><span class="lineno"> 1052</span>            scores(i, j) *= scale;</div>
<div class="line"><a id="l01053" name="l01053"></a><span class="lineno"> 1053</span>            scores(i, j) = std::min(scores(i, j), max_score);</div>
<div class="line"><a id="l01054" name="l01054"></a><span class="lineno"> 1054</span>            row_max = std::max(row_max, scores(i, j));</div>
<div class="line"><a id="l01055" name="l01055"></a><span class="lineno"> 1055</span>        }</div>
<div class="line"><a id="l01056" name="l01056"></a><span class="lineno"> 1056</span> </div>
<div class="line"><a id="l01057" name="l01057"></a><span class="lineno"> 1057</span>        <span class="comment">// Compute softmax with improved numerical stability</span></div>
<div class="line"><a id="l01058" name="l01058"></a><span class="lineno"> 1058</span>        <span class="keywordtype">float</span> sum_exp = 0.0f;</div>
<div class="line"><a id="l01059" name="l01059"></a><span class="lineno"> 1059</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; scores.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); ++j) {</div>
<div class="line"><a id="l01060" name="l01060"></a><span class="lineno"> 1060</span>            scores(i, j) = std::exp(scores(i, j) - row_max);</div>
<div class="line"><a id="l01061" name="l01061"></a><span class="lineno"> 1061</span>            sum_exp += scores(i, j);</div>
<div class="line"><a id="l01062" name="l01062"></a><span class="lineno"> 1062</span>        }</div>
<div class="line"><a id="l01063" name="l01063"></a><span class="lineno"> 1063</span> </div>
<div class="line"><a id="l01064" name="l01064"></a><span class="lineno"> 1064</span>        <span class="comment">// Normalize with careful handling of small values</span></div>
<div class="line"><a id="l01065" name="l01065"></a><span class="lineno"> 1065</span>        <span class="keyword">const</span> <span class="keywordtype">float</span> eps = 1e-6f;</div>
<div class="line"><a id="l01066" name="l01066"></a><span class="lineno"> 1066</span>        <span class="keywordflow">if</span> (sum_exp &lt; eps)</div>
<div class="line"><a id="l01067" name="l01067"></a><span class="lineno"> 1067</span>            sum_exp = eps;</div>
<div class="line"><a id="l01068" name="l01068"></a><span class="lineno"> 1068</span> </div>
<div class="line"><a id="l01069" name="l01069"></a><span class="lineno"> 1069</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; scores.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); ++j) {</div>
<div class="line"><a id="l01070" name="l01070"></a><span class="lineno"> 1070</span>            scores(i, j) /= sum_exp;</div>
<div class="line"><a id="l01071" name="l01071"></a><span class="lineno"> 1071</span>        }</div>
<div class="line"><a id="l01072" name="l01072"></a><span class="lineno"> 1072</span>    }</div>
<div class="line"><a id="l01073" name="l01073"></a><span class="lineno"> 1073</span> </div>
<div class="line"><a id="l01074" name="l01074"></a><span class="lineno"> 1074</span>    <span class="keywordflow">return</span> scores;</div>
<div class="line"><a id="l01075" name="l01075"></a><span class="lineno"> 1075</span>}</div>
</div>
<div class="line"><a id="l01076" name="l01076"></a><span class="lineno"> 1076</span> </div>
<div class="foldopen" id="foldopen01077" data-start="{" data-end="}">
<div class="line"><a id="l01077" name="l01077"></a><span class="lineno"><a class="line" href="classMultiHeadAttention.html#a666bd13dfa5833931c2b3176ebf3d2f8"> 1077</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classMultiHeadAttention.html#a666bd13dfa5833931c2b3176ebf3d2f8">MultiHeadAttention::apply_stable_softmax</a>(<a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; x)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l01078" name="l01078"></a><span class="lineno"> 1078</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> EPSILON = 1e-8f;</div>
<div class="line"><a id="l01079" name="l01079"></a><span class="lineno"> 1079</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> TEMPERATURE = 0.7f;</div>
<div class="line"><a id="l01080" name="l01080"></a><span class="lineno"> 1080</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> MIN_SCORE = -1e4f;</div>
<div class="line"><a id="l01081" name="l01081"></a><span class="lineno"> 1081</span> </div>
<div class="line"><a id="l01082" name="l01082"></a><span class="lineno"> 1082</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; x.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(); i++) {</div>
<div class="line"><a id="l01083" name="l01083"></a><span class="lineno"> 1083</span>        <span class="comment">// Find max for numerical stability</span></div>
<div class="line"><a id="l01084" name="l01084"></a><span class="lineno"> 1084</span>        <span class="keywordtype">float</span> max_val = MIN_SCORE;</div>
<div class="line"><a id="l01085" name="l01085"></a><span class="lineno"> 1085</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; x.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l01086" name="l01086"></a><span class="lineno"> 1086</span>            <span class="keywordflow">if</span> (x(i, j) &gt; MIN_SCORE) {</div>
<div class="line"><a id="l01087" name="l01087"></a><span class="lineno"> 1087</span>                max_val = std::max(max_val, x(i, j));</div>
<div class="line"><a id="l01088" name="l01088"></a><span class="lineno"> 1088</span>            }</div>
<div class="line"><a id="l01089" name="l01089"></a><span class="lineno"> 1089</span>        }</div>
<div class="line"><a id="l01090" name="l01090"></a><span class="lineno"> 1090</span> </div>
<div class="line"><a id="l01091" name="l01091"></a><span class="lineno"> 1091</span>        <span class="comment">// Apply temperature scaling and compute sum</span></div>
<div class="line"><a id="l01092" name="l01092"></a><span class="lineno"> 1092</span>        <span class="keywordtype">float</span> sum_exp = 0.0f;</div>
<div class="line"><a id="l01093" name="l01093"></a><span class="lineno"> 1093</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; x.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l01094" name="l01094"></a><span class="lineno"> 1094</span>            <span class="keywordflow">if</span> (x(i, j) &gt; MIN_SCORE) {</div>
<div class="line"><a id="l01095" name="l01095"></a><span class="lineno"> 1095</span>                x(i, j) = std::exp((x(i, j) - max_val) / TEMPERATURE);</div>
<div class="line"><a id="l01096" name="l01096"></a><span class="lineno"> 1096</span>                sum_exp += x(i, j);</div>
<div class="line"><a id="l01097" name="l01097"></a><span class="lineno"> 1097</span>            } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l01098" name="l01098"></a><span class="lineno"> 1098</span>                x(i, j) = 0.0f;</div>
<div class="line"><a id="l01099" name="l01099"></a><span class="lineno"> 1099</span>            }</div>
<div class="line"><a id="l01100" name="l01100"></a><span class="lineno"> 1100</span>        }</div>
<div class="line"><a id="l01101" name="l01101"></a><span class="lineno"> 1101</span> </div>
<div class="line"><a id="l01102" name="l01102"></a><span class="lineno"> 1102</span>        <span class="comment">// Normalize</span></div>
<div class="line"><a id="l01103" name="l01103"></a><span class="lineno"> 1103</span>        <span class="keywordflow">if</span> (sum_exp &lt; EPSILON) {</div>
<div class="line"><a id="l01104" name="l01104"></a><span class="lineno"> 1104</span>            <span class="comment">// If sum is too small, use uniform distribution</span></div>
<div class="line"><a id="l01105" name="l01105"></a><span class="lineno"> 1105</span>            <span class="keywordtype">float</span> uniform_val = 1.0f / x.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>();</div>
<div class="line"><a id="l01106" name="l01106"></a><span class="lineno"> 1106</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; x.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l01107" name="l01107"></a><span class="lineno"> 1107</span>                x(i, j) = uniform_val;</div>
<div class="line"><a id="l01108" name="l01108"></a><span class="lineno"> 1108</span>            }</div>
<div class="line"><a id="l01109" name="l01109"></a><span class="lineno"> 1109</span>        } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l01110" name="l01110"></a><span class="lineno"> 1110</span>            <span class="comment">// Normal normalization</span></div>
<div class="line"><a id="l01111" name="l01111"></a><span class="lineno"> 1111</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; x.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l01112" name="l01112"></a><span class="lineno"> 1112</span>                x(i, j) /= sum_exp;</div>
<div class="line"><a id="l01113" name="l01113"></a><span class="lineno"> 1113</span>            }</div>
<div class="line"><a id="l01114" name="l01114"></a><span class="lineno"> 1114</span>        }</div>
<div class="line"><a id="l01115" name="l01115"></a><span class="lineno"> 1115</span>    }</div>
<div class="line"><a id="l01116" name="l01116"></a><span class="lineno"> 1116</span>}</div>
</div>
<div class="ttc" id="aattention_8cpp_html_a420192cf7ad6664706c6e334d57142ff"><div class="ttname"><a href="attention_8cpp.html#a420192cf7ad6664706c6e334d57142ff">metrics</a></div><div class="ttdeci">PerformanceMetrics metrics</div><div class="ttdef"><b>Definition</b> <a href="main_8cpp_source.html#l00008">main.cpp:8</a></div></div>
<div class="ttc" id="aattention_8hpp_html"><div class="ttname"><a href="attention_8hpp.html">attention.hpp</a></div></div>
<div class="ttc" id="aclassAttentionMask_html"><div class="ttname"><a href="classAttentionMask.html">AttentionMask</a></div><div class="ttdoc">Class representing attention masks used in transformer attention mechanisms.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00016">attention.hpp:16</a></div></div>
<div class="ttc" id="aclassAttentionMask_html_a12b920e427facb6c1152fb7463291287"><div class="ttname"><a href="classAttentionMask.html#a12b920e427facb6c1152fb7463291287">AttentionMask::create_causal_mask</a></div><div class="ttdeci">static AttentionMask create_causal_mask(size_t size)</div><div class="ttdoc">Creates a causal (triangular) mask for autoregressive attention.</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00850">attention.cpp:850</a></div></div>
<div class="ttc" id="aclassAttentionMask_html_a1a57ddbfcbf2055513909090747d063e"><div class="ttname"><a href="classAttentionMask.html#a1a57ddbfcbf2055513909090747d063e">AttentionMask::mask</a></div><div class="ttdeci">Matrix mask</div><div class="ttdoc">The actual mask matrix where 0 indicates masked positions.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00018">attention.hpp:18</a></div></div>
<div class="ttc" id="aclassAttentionMask_html_a75f94e4bb34636e221d76c1bbad8bc5a"><div class="ttname"><a href="classAttentionMask.html#a75f94e4bb34636e221d76c1bbad8bc5a">AttentionMask::create_padding_mask</a></div><div class="ttdeci">static AttentionMask create_padding_mask(const std::vector&lt; int &gt; &amp;lengths, size_t max_len)</div><div class="ttdoc">Creates a padding mask for variable length sequences.</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00863">attention.cpp:863</a></div></div>
<div class="ttc" id="aclassGroupedQueryAttention_html"><div class="ttname"><a href="classGroupedQueryAttention.html">GroupedQueryAttention</a></div><div class="ttdoc">Implements Grouped Query Attention for efficient transformer attention.</div><div class="ttdef"><b>Definition</b> <a href="gqa_8hpp_source.html#l00017">gqa.hpp:17</a></div></div>
<div class="ttc" id="aclassGroupedQueryAttention_html_ad84a75705d197a794de0d3971e656a45"><div class="ttname"><a href="classGroupedQueryAttention.html#ad84a75705d197a794de0d3971e656a45">GroupedQueryAttention::forward</a></div><div class="ttdeci">Matrix forward(const Matrix &amp;x, const AttentionMask &amp;mask, const std::optional&lt; KVCache &gt; &amp;kv_cache=std::nullopt)</div><div class="ttdoc">Performs the forward pass of grouped query attention.</div><div class="ttdef"><b>Definition</b> <a href="gqa_8cpp_source.html#l00086">gqa.cpp:86</a></div></div>
<div class="ttc" id="aclassHalfPrecisionTraining_html_a82deaaee41c1b5d49adf8049b9a0d2e3"><div class="ttname"><a href="classHalfPrecisionTraining.html#a82deaaee41c1b5d49adf8049b9a0d2e3">HalfPrecisionTraining::convert_to_fp16</a></div><div class="ttdeci">static void convert_to_fp16(Matrix &amp;matrix)</div><div class="ttdoc">Converts a matrix from FP32 to FP16 format.</div><div class="ttdef"><b>Definition</b> <a href="half__precision_8cpp_source.html#l00029">half_precision.cpp:29</a></div></div>
<div class="ttc" id="aclassHalfPrecisionTraining_html_aa968c90058884f141bdc068b6ff64b9b"><div class="ttname"><a href="classHalfPrecisionTraining.html#aa968c90058884f141bdc068b6ff64b9b">HalfPrecisionTraining::convert_to_fp32</a></div><div class="ttdeci">static void convert_to_fp32(Matrix &amp;matrix)</div><div class="ttdoc">Converts a matrix from FP16 back to FP32 format.</div><div class="ttdef"><b>Definition</b> <a href="half__precision_8cpp_source.html#l00100">half_precision.cpp:100</a></div></div>
<div class="ttc" id="aclassMatrix_html"><div class="ttname"><a href="classMatrix.html">Matrix</a></div><div class="ttdoc">A 2D matrix class optimized for neural network operations.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00031">matrix.hpp:31</a></div></div>
<div class="ttc" id="aclassMatrix_html_a6efb67c1b998ea7ffdc0a1e1b4252e62"><div class="ttname"><a href="classMatrix.html#a6efb67c1b998ea7ffdc0a1e1b4252e62">Matrix::empty</a></div><div class="ttdeci">bool empty() const</div><div class="ttdoc">Checks if the matrix is empty.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00119">matrix.hpp:119</a></div></div>
<div class="ttc" id="aclassMatrix_html_a759661b75b9681f3a89ff75e27933b3a"><div class="ttname"><a href="classMatrix.html#a759661b75b9681f3a89ff75e27933b3a">Matrix::transpose</a></div><div class="ttdeci">Matrix transpose() const</div><div class="ttdoc">Computes the matrix transpose.</div><div class="ttdef"><b>Definition</b> <a href="components_8cpp_source.html#l00153">components.cpp:153</a></div></div>
<div class="ttc" id="aclassMatrix_html_a7a12d2cbbf595077f94c5e73bc6bc04a"><div class="ttname"><a href="classMatrix.html#a7a12d2cbbf595077f94c5e73bc6bc04a">Matrix::at</a></div><div class="ttdeci">float &amp; at(size_t row, size_t col)</div><div class="ttdoc">Safe element access with bounds checking.</div><div class="ttdef"><b>Definition</b> <a href="components_8cpp_source.html#l00126">components.cpp:126</a></div></div>
<div class="ttc" id="aclassMatrix_html_a864bfe1ae2f2a1eb34453bb8206c695f"><div class="ttname"><a href="classMatrix.html#a864bfe1ae2f2a1eb34453bb8206c695f">Matrix::block</a></div><div class="ttdeci">Matrix block(size_t start_row, size_t start_col, size_t num_rows, size_t num_cols) const</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00264">matrix.hpp:264</a></div></div>
<div class="ttc" id="aclassMatrix_html_a8c8b8a4a34ad4a16e6ba28a62010dfa0"><div class="ttname"><a href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">Matrix::cols</a></div><div class="ttdeci">size_t cols() const</div><div class="ttdoc">Gets the number of columns.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00087">matrix.hpp:87</a></div></div>
<div class="ttc" id="aclassMatrix_html_a95e1fcffce26339f95f1353a4193aac2"><div class="ttname"><a href="classMatrix.html#a95e1fcffce26339f95f1353a4193aac2">Matrix::row_sum</a></div><div class="ttdeci">Vector row_sum() const</div><div class="ttdef"><b>Definition</b> <a href="components_8cpp_source.html#l00339">components.cpp:339</a></div></div>
<div class="ttc" id="aclassMatrix_html_a97617f3524bfa47d6ac7daa0eefc1941"><div class="ttname"><a href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">Matrix::rows</a></div><div class="ttdeci">size_t rows() const</div><div class="ttdoc">Gets the number of rows.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00079">matrix.hpp:79</a></div></div>
<div class="ttc" id="aclassMatrix_html_a97f36647d60f005b37da2f51f21837d4"><div class="ttname"><a href="classMatrix.html#a97f36647d60f005b37da2f51f21837d4">Matrix::randomize</a></div><div class="ttdeci">void randomize(float min_val, float max_val)</div><div class="ttdef"><b>Definition</b> <a href="components_8cpp_source.html#l00330">components.cpp:330</a></div></div>
<div class="ttc" id="aclassMatrix_html_ab09991ab01bd0b5db9dec6000c36089c"><div class="ttname"><a href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">Matrix::data</a></div><div class="ttdeci">const float * data() const</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00359">matrix.hpp:359</a></div></div>
<div class="ttc" id="aclassMatrix_html_ac0a0302810135d32909eaa819fd3d220"><div class="ttname"><a href="classMatrix.html#ac0a0302810135d32909eaa819fd3d220">Matrix::max</a></div><div class="ttdeci">float max() const</div><div class="ttdoc">Gets the maximum value in the matrix.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00135">matrix.hpp:135</a></div></div>
<div class="ttc" id="aclassMatrix_html_ac5cf026a1e0349e348c67f285271d417"><div class="ttname"><a href="classMatrix.html#ac5cf026a1e0349e348c67f285271d417">Matrix::load</a></div><div class="ttdeci">static Matrix load(std::istream &amp;is)</div><div class="ttdef"><b>Definition</b> <a href="components_8cpp_source.html#l00320">components.cpp:320</a></div></div>
<div class="ttc" id="aclassMatrix_html_ad0b2d0782d21b8269d3dde66518bb66b"><div class="ttname"><a href="classMatrix.html#ad0b2d0782d21b8269d3dde66518bb66b">Matrix::min</a></div><div class="ttdeci">float min() const</div><div class="ttdoc">Gets the minimum value in the matrix.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00127">matrix.hpp:127</a></div></div>
<div class="ttc" id="aclassMatrix_html_aeb6be0338f7e26667962470f4766120b"><div class="ttname"><a href="classMatrix.html#aeb6be0338f7e26667962470f4766120b">Matrix::size</a></div><div class="ttdeci">size_t size() const</div><div class="ttdoc">Gets the total number of elements.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00095">matrix.hpp:95</a></div></div>
<div class="ttc" id="aclassMatrix_html_aefe021b305effc8062930719bcd532ef"><div class="ttname"><a href="classMatrix.html#aefe021b305effc8062930719bcd532ef">Matrix::save</a></div><div class="ttdeci">void save(std::ostream &amp;os) const</div><div class="ttdef"><b>Definition</b> <a href="components_8cpp_source.html#l00314">components.cpp:314</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a02d15d5c760c9461189debefe54dab99"><div class="ttname"><a href="classMultiHeadAttention.html#a02d15d5c760c9461189debefe54dab99">MultiHeadAttention::get_cos_cached</a></div><div class="ttdeci">float get_cos_cached(size_t pos, size_t dim_idx) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l01023">attention.cpp:1023</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a0386f6537c985151921e37a2008d6d59"><div class="ttname"><a href="classMultiHeadAttention.html#a0386f6537c985151921e37a2008d6d59">MultiHeadAttention::save</a></div><div class="ttdeci">void save(std::ostream &amp;os) const</div><div class="ttdoc">Saves the attention layer parameters to a stream.</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00364">attention.cpp:364</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a0afc6064aba014f541fc9e2c4cf09841"><div class="ttname"><a href="classMultiHeadAttention.html#a0afc6064aba014f541fc9e2c4cf09841">MultiHeadAttention::query_bias</a></div><div class="ttdeci">FloatVector query_bias</div><div class="ttdoc">Query projection bias.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00281">attention.hpp:281</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a0d5c79966001a4f69b95c8fdcad85e2b"><div class="ttname"><a href="classMultiHeadAttention.html#a0d5c79966001a4f69b95c8fdcad85e2b">MultiHeadAttention::backward</a></div><div class="ttdeci">Matrix backward(const Matrix &amp;grad_output, const Matrix &amp;input, const Matrix &amp;target_distribution)</div><div class="ttdoc">Performs the backward pass to compute gradients.</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00663">attention.cpp:663</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a0df29ad720ff58e8ffd73d3fcb2e6b26"><div class="ttname"><a href="classMultiHeadAttention.html#a0df29ad720ff58e8ffd73d3fcb2e6b26">MultiHeadAttention::compute_attention</a></div><div class="ttdeci">Tensor compute_attention(const Matrix &amp;Q, const Matrix &amp;K, const Matrix &amp;V, const AttentionMask &amp;mask, size_t batch_size, size_t num_heads, size_t seq_len, size_t head_size)</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00878">attention.cpp:878</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a15a9a52d7adb5b6c4fe5cddb273acff6"><div class="ttname"><a href="classMultiHeadAttention.html#a15a9a52d7adb5b6c4fe5cddb273acff6">MultiHeadAttention::apply_rope</a></div><div class="ttdeci">Vector apply_rope(const Vector &amp;x, size_t position) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00016">attention.cpp:16</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a18362671ef7860ee292602e8a80fdfe3"><div class="ttname"><a href="classMultiHeadAttention.html#a18362671ef7860ee292602e8a80fdfe3">MultiHeadAttention::query_proj</a></div><div class="ttdeci">Matrix query_proj</div><div class="ttdoc">Query projection matrix [hidden_size, num_heads * head_dim].</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00275">attention.hpp:275</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a1e6e670e0c4ab3ef36a100394220fd07"><div class="ttname"><a href="classMultiHeadAttention.html#a1e6e670e0c4ab3ef36a100394220fd07">MultiHeadAttention::head_dim</a></div><div class="ttdeci">size_t head_dim</div><div class="ttdoc">Dimension of each attention head.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00288">attention.hpp:288</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a25d0ca82bde81799ff028d4f4d276806"><div class="ttname"><a href="classMultiHeadAttention.html#a25d0ca82bde81799ff028d4f4d276806">MultiHeadAttention::window_size</a></div><div class="ttdeci">size_t window_size</div><div class="ttdoc">Size of attention window.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00294">attention.hpp:294</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a2ae83b92dbfb2da91f2a158d17c701ff"><div class="ttname"><a href="classMultiHeadAttention.html#a2ae83b92dbfb2da91f2a158d17c701ff">MultiHeadAttention::flash_attention</a></div><div class="ttdeci">Matrix flash_attention(const Matrix &amp;Q, const Matrix &amp;K, const Matrix &amp;V, const AttentionMask &amp;mask) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00053">attention.cpp:53</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a2af0984f2e552f9bbad0eb9a4f33e1dc"><div class="ttname"><a href="classMultiHeadAttention.html#a2af0984f2e552f9bbad0eb9a4f33e1dc">MultiHeadAttention::compute_key_gradients</a></div><div class="ttdeci">Matrix compute_key_gradients(const Matrix &amp;grad_output, const Matrix &amp;input) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00337">attention.hpp:337</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a34cbd06de38900793f5c452507b032fa"><div class="ttname"><a href="classMultiHeadAttention.html#a34cbd06de38900793f5c452507b032fa">MultiHeadAttention::num_heads</a></div><div class="ttdeci">size_t num_heads</div><div class="ttdoc">Number of attention heads.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00287">attention.hpp:287</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a36b374cd10b12a404825b10ca5371096"><div class="ttname"><a href="classMultiHeadAttention.html#a36b374cd10b12a404825b10ca5371096">MultiHeadAttention::compute_attention_scores</a></div><div class="ttdeci">Matrix compute_attention_scores(const Matrix &amp;Q, const Matrix &amp;K)</div><div class="ttdoc">Computes attention scores between query and key matrices.</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l01039">attention.cpp:1039</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a3ccbdfe184867bfb5ba90cd103bd2eb0"><div class="ttname"><a href="classMultiHeadAttention.html#a3ccbdfe184867bfb5ba90cd103bd2eb0">MultiHeadAttention::apply_mask</a></div><div class="ttdeci">void apply_mask(Matrix &amp;scores, const Matrix &amp;mask) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00370">attention.hpp:370</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a3e04836c7b83bb0172fd3d9a120c8239"><div class="ttname"><a href="classMultiHeadAttention.html#a3e04836c7b83bb0172fd3d9a120c8239">MultiHeadAttention::output_bias</a></div><div class="ttdeci">FloatVector output_bias</div><div class="ttdoc">Output projection bias.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00284">attention.hpp:284</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a4314826233aeaa0ba472897dbb1ee7e9"><div class="ttname"><a href="classMultiHeadAttention.html#a4314826233aeaa0ba472897dbb1ee7e9">MultiHeadAttention::use_fp16_</a></div><div class="ttdeci">bool use_fp16_</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00429">attention.hpp:429</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a4385a8aebf34df120d848956d8f510c5"><div class="ttname"><a href="classMultiHeadAttention.html#a4385a8aebf34df120d848956d8f510c5">MultiHeadAttention::output_proj_grad</a></div><div class="ttdeci">Matrix output_proj_grad</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00268">attention.hpp:268</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a43b9f09cb611795b1642d239aaa502b6"><div class="ttname"><a href="classMultiHeadAttention.html#a43b9f09cb611795b1642d239aaa502b6">MultiHeadAttention::value_bias</a></div><div class="ttdeci">FloatVector value_bias</div><div class="ttdoc">Value projection bias.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00283">attention.hpp:283</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a49435188dcf74478d543f7f4124bd25d"><div class="ttname"><a href="classMultiHeadAttention.html#a49435188dcf74478d543f7f4124bd25d">MultiHeadAttention::use_flash</a></div><div class="ttdeci">bool use_flash</div><div class="ttdoc">Whether to use Flash Attention.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00292">attention.hpp:292</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a4a1b86106c4351af679f4e0e2a8a0811"><div class="ttname"><a href="classMultiHeadAttention.html#a4a1b86106c4351af679f4e0e2a8a0811">MultiHeadAttention::output_proj</a></div><div class="ttdeci">Matrix output_proj</div><div class="ttdoc">Output projection matrix [num_heads * head_dim, hidden_size].</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00278">attention.hpp:278</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a5549a32f6e8ee18e5e69d7a56f1365de"><div class="ttname"><a href="classMultiHeadAttention.html#a5549a32f6e8ee18e5e69d7a56f1365de">MultiHeadAttention::cos_cached</a></div><div class="ttdeci">Matrix cos_cached</div><div class="ttdoc">Cached cosine values for RoPE.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00299">attention.hpp:299</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a58478592fe138677a9a9b923460dfaef"><div class="ttname"><a href="classMultiHeadAttention.html#a58478592fe138677a9a9b923460dfaef">MultiHeadAttention::use_gqa</a></div><div class="ttdeci">bool use_gqa</div><div class="ttdoc">Whether to use grouped query attention.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00295">attention.hpp:295</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a595e7485ec3665e5dae0b13e820a529b"><div class="ttname"><a href="classMultiHeadAttention.html#a595e7485ec3665e5dae0b13e820a529b">MultiHeadAttention::validate_dimensions</a></div><div class="ttdeci">void validate_dimensions(const Matrix &amp;grad_output, const Matrix &amp;input, const Matrix &amp;target_dist) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00318">attention.hpp:318</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a5b61a3ff6c0d3debbf2c73e3a110aecc"><div class="ttname"><a href="classMultiHeadAttention.html#a5b61a3ff6c0d3debbf2c73e3a110aecc">MultiHeadAttention::num_kv_heads</a></div><div class="ttdeci">size_t num_kv_heads</div><div class="ttdoc">Number of key/value heads for GQA.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00296">attention.hpp:296</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a62c5dc456e39aa00650e69315fe86af3"><div class="ttname"><a href="classMultiHeadAttention.html#a62c5dc456e39aa00650e69315fe86af3">MultiHeadAttention::query_proj_grad</a></div><div class="ttdeci">Matrix query_proj_grad</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00265">attention.hpp:265</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a666bd13dfa5833931c2b3176ebf3d2f8"><div class="ttname"><a href="classMultiHeadAttention.html#a666bd13dfa5833931c2b3176ebf3d2f8">MultiHeadAttention::apply_stable_softmax</a></div><div class="ttdeci">void apply_stable_softmax(Matrix &amp;x) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l01077">attention.cpp:1077</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a6cc7e11046066e5d752d9112c56d16f2"><div class="ttname"><a href="classMultiHeadAttention.html#a6cc7e11046066e5d752d9112c56d16f2">MultiHeadAttention::initialize_rope_cache</a></div><div class="ttdeci">void initialize_rope_cache(size_t max_seq_len, size_t dim_idx)</div><div class="ttdoc">Initializes or updates RoPE caches.</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00998">attention.cpp:998</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a6e2075c78c6a20f11ea661d31ecffa32"><div class="ttname"><a href="classMultiHeadAttention.html#a6e2075c78c6a20f11ea661d31ecffa32">MultiHeadAttention::combine_gradients</a></div><div class="ttdeci">Matrix combine_gradients(const Matrix &amp;dQ, const Matrix &amp;dK, const Matrix &amp;dV) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00349">attention.hpp:349</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a6eaf4f61461419d9b2273d8ea5b61c8c"><div class="ttname"><a href="classMultiHeadAttention.html#a6eaf4f61461419d9b2273d8ea5b61c8c">MultiHeadAttention::use_rope</a></div><div class="ttdeci">bool use_rope</div><div class="ttdoc">Whether to use rotary position embeddings.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00291">attention.hpp:291</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a8637aa0a25d31fc7f4713f916bb1f043"><div class="ttname"><a href="classMultiHeadAttention.html#a8637aa0a25d31fc7f4713f916bb1f043">MultiHeadAttention::value_proj_grad</a></div><div class="ttdeci">Matrix value_proj_grad</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00267">attention.hpp:267</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a872be590c370844a88aff0705d1cba72"><div class="ttname"><a href="classMultiHeadAttention.html#a872be590c370844a88aff0705d1cba72">MultiHeadAttention::key_bias_grad</a></div><div class="ttdeci">FloatVector key_bias_grad</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00270">attention.hpp:270</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a891d285712cdbb98de1b453c58c23cc4"><div class="ttname"><a href="classMultiHeadAttention.html#a891d285712cdbb98de1b453c58c23cc4">MultiHeadAttention::output_bias_grad</a></div><div class="ttdeci">FloatVector output_bias_grad</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00272">attention.hpp:272</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a944d2e4a686b408e94758c7458888f47"><div class="ttname"><a href="classMultiHeadAttention.html#a944d2e4a686b408e94758c7458888f47">MultiHeadAttention::query_bias_grad</a></div><div class="ttdeci">FloatVector query_bias_grad</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00269">attention.hpp:269</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_a9c5b1b6ba053f3891ddde42588fb8e7e"><div class="ttname"><a href="classMultiHeadAttention.html#a9c5b1b6ba053f3891ddde42588fb8e7e">MultiHeadAttention::forward</a></div><div class="ttdeci">Matrix forward(const Matrix &amp;x, const AttentionMask &amp;mask, const std::optional&lt; KVCache &gt; &amp;kv_cache=std::nullopt)</div><div class="ttdoc">Performs the forward pass of the attention mechanism.</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00139">attention.cpp:139</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_aa153e5d1204e9e40db741b979b8da86d"><div class="ttname"><a href="classMultiHeadAttention.html#aa153e5d1204e9e40db741b979b8da86d">MultiHeadAttention::compute_query_gradients</a></div><div class="ttdeci">Matrix compute_query_gradients(const Matrix &amp;grad_output, const Matrix &amp;input) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00331">attention.hpp:331</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_aa63f2eb55c928afcbaabe2bed9b5fe9f"><div class="ttname"><a href="classMultiHeadAttention.html#aa63f2eb55c928afcbaabe2bed9b5fe9f">MultiHeadAttention::standard_attention</a></div><div class="ttdeci">Matrix standard_attention(const Matrix &amp;Q, const Matrix &amp;K, const Matrix &amp;V, const AttentionMask &amp;mask)</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00566">attention.cpp:566</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_aad0999daf1477b120755a3413685812b"><div class="ttname"><a href="classMultiHeadAttention.html#aad0999daf1477b120755a3413685812b">MultiHeadAttention::value_proj</a></div><div class="ttdeci">Matrix value_proj</div><div class="ttdoc">Value projection matrix [hidden_size, num_kv_heads * head_dim].</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00277">attention.hpp:277</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_aaffc8817085cfdbcdbebf858d6ff71ba"><div class="ttname"><a href="classMultiHeadAttention.html#aaffc8817085cfdbcdbebf858d6ff71ba">MultiHeadAttention::use_sliding_window</a></div><div class="ttdeci">bool use_sliding_window</div><div class="ttdoc">Whether to use sliding window attention.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00293">attention.hpp:293</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_ac034c448395ee5ccb2f55f801ccaec40"><div class="ttname"><a href="classMultiHeadAttention.html#ac034c448395ee5ccb2f55f801ccaec40">MultiHeadAttention::key_bias</a></div><div class="ttdeci">FloatVector key_bias</div><div class="ttdoc">Key projection bias.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00282">attention.hpp:282</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_acdb722e2273e30fee53d5dc11d60e956"><div class="ttname"><a href="classMultiHeadAttention.html#acdb722e2273e30fee53d5dc11d60e956">MultiHeadAttention::load</a></div><div class="ttdeci">static std::unique_ptr&lt; MultiHeadAttention &gt; load(std::istream &amp;is, const TransformerConfig &amp;config)</div><div class="ttdoc">Loads attention layer parameters from a stream.</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00391">attention.cpp:391</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_ad02e8c0946a244a380de6a145afbce7b"><div class="ttname"><a href="classMultiHeadAttention.html#ad02e8c0946a244a380de6a145afbce7b">MultiHeadAttention::get_sin_cached</a></div><div class="ttdeci">float get_sin_cached(size_t pos, size_t dim_idx) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l01031">attention.cpp:1031</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_ad4b2bd9329b13739e3070253fa707abb"><div class="ttname"><a href="classMultiHeadAttention.html#ad4b2bd9329b13739e3070253fa707abb">MultiHeadAttention::dropout_prob</a></div><div class="ttdeci">float dropout_prob</div><div class="ttdoc">Dropout probability.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00290">attention.hpp:290</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_ad58475dba6a9acf0f788a069807ca678"><div class="ttname"><a href="classMultiHeadAttention.html#ad58475dba6a9acf0f788a069807ca678">MultiHeadAttention::reshape_for_attention</a></div><div class="ttdeci">Tensor reshape_for_attention(const Matrix &amp;x, size_t batch_size, size_t num_heads, size_t seq_len, size_t head_size) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00725">attention.cpp:725</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_adccbc1658f1f13e00ea1a7cb71ec9030"><div class="ttname"><a href="classMultiHeadAttention.html#adccbc1658f1f13e00ea1a7cb71ec9030">MultiHeadAttention::key_proj</a></div><div class="ttdeci">Matrix key_proj</div><div class="ttdoc">Key projection matrix [hidden_size, num_kv_heads * head_dim].</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00276">attention.hpp:276</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_aded8e7c09f874cc1aa73f9da805a3ec6"><div class="ttname"><a href="classMultiHeadAttention.html#aded8e7c09f874cc1aa73f9da805a3ec6">MultiHeadAttention::key_proj_grad</a></div><div class="ttdeci">Matrix key_proj_grad</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00266">attention.hpp:266</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_aef4835723fe043b288a6ac6af6299159"><div class="ttname"><a href="classMultiHeadAttention.html#aef4835723fe043b288a6ac6af6299159">MultiHeadAttention::sin_cached</a></div><div class="ttdeci">Matrix sin_cached</div><div class="ttdoc">Cached sine values for RoPE.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00300">attention.hpp:300</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_afa3559e2a63108418d209926f89d7f13"><div class="ttname"><a href="classMultiHeadAttention.html#afa3559e2a63108418d209926f89d7f13">MultiHeadAttention::hidden_size</a></div><div class="ttdeci">size_t hidden_size</div><div class="ttdoc">Size of input and output tensors.</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00289">attention.hpp:289</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_afa3b408cc8580772c3bdc32b5e25fe07"><div class="ttname"><a href="classMultiHeadAttention.html#afa3b408cc8580772c3bdc32b5e25fe07">MultiHeadAttention::value_bias_grad</a></div><div class="ttdeci">FloatVector value_bias_grad</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00271">attention.hpp:271</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_afb26ebaa99dac3ec111eeeb60baf96cf"><div class="ttname"><a href="classMultiHeadAttention.html#afb26ebaa99dac3ec111eeeb60baf96cf">MultiHeadAttention::compute_value_gradients</a></div><div class="ttdeci">Matrix compute_value_gradients(const Matrix &amp;grad_output, const Matrix &amp;input) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8hpp_source.html#l00343">attention.hpp:343</a></div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_afd7c283ed2457ad7304567c897b3d877"><div class="ttname"><a href="classMultiHeadAttention.html#afd7c283ed2457ad7304567c897b3d877">MultiHeadAttention::MultiHeadAttention</a></div><div class="ttdeci">MultiHeadAttention()=default</div></div>
<div class="ttc" id="aclassMultiHeadAttention_html_aff569533c7e7f11a7fa4b6ba1662efc5"><div class="ttname"><a href="classMultiHeadAttention.html#aff569533c7e7f11a7fa4b6ba1662efc5">MultiHeadAttention::reshape_from_attention</a></div><div class="ttdeci">Matrix reshape_from_attention(const Tensor &amp;x, size_t seq_len, size_t hidden_size) const</div><div class="ttdef"><b>Definition</b> <a href="attention_8cpp_source.html#l00746">attention.cpp:746</a></div></div>
<div class="ttc" id="aclassPerformanceMetrics_html"><div class="ttname"><a href="classPerformanceMetrics.html">PerformanceMetrics</a></div><div class="ttdoc">Performance monitoring and profiling for transformer operations.</div><div class="ttdef"><b>Definition</b> <a href="performance__metrics_8hpp_source.html#l00017">performance_metrics.hpp:17</a></div></div>
<div class="ttc" id="aclassPerformanceMetrics_html_a906fa724ba88cb06250ef1624f494114"><div class="ttname"><a href="classPerformanceMetrics.html#a906fa724ba88cb06250ef1624f494114">PerformanceMetrics::stop_timer</a></div><div class="ttdeci">void stop_timer(const std::string &amp;name)</div><div class="ttdoc">Stops timing an operation.</div><div class="ttdef"><b>Definition</b> <a href="performance__metrics_8cpp_source.html#l00009">performance_metrics.cpp:9</a></div></div>
<div class="ttc" id="aclassPerformanceMetrics_html_aab6bfb13b95e4b95ff6b1aa0e0ba50e3"><div class="ttname"><a href="classPerformanceMetrics.html#aab6bfb13b95e4b95ff6b1aa0e0ba50e3">PerformanceMetrics::start_timer</a></div><div class="ttdeci">void start_timer(const std::string &amp;name)</div><div class="ttdoc">Starts timing an operation.</div><div class="ttdef"><b>Definition</b> <a href="performance__metrics_8cpp_source.html#l00005">performance_metrics.cpp:5</a></div></div>
<div class="ttc" id="aclassPerformanceMetrics_html_ae1c4afd36fc5c55685cd183fa80c1125"><div class="ttname"><a href="classPerformanceMetrics.html#ae1c4afd36fc5c55685cd183fa80c1125">PerformanceMetrics::record_attention_flops</a></div><div class="ttdeci">void record_attention_flops(size_t seq_length, size_t num_heads, size_t head_dim)</div><div class="ttdoc">Records FLOPs for an attention operation.</div><div class="ttdef"><b>Definition</b> <a href="performance__metrics_8cpp_source.html#l00043">performance_metrics.cpp:43</a></div></div>
<div class="ttc" id="aclassTensor_html"><div class="ttname"><a href="classTensor.html">Tensor</a></div><div class="ttdoc">A 4-dimensional tensor class for neural network computations.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8hpp_source.html#l00017">tensor.hpp:17</a></div></div>
<div class="ttc" id="aclassTensor_html_a54a0edc085929b2b462574a6a80892b0"><div class="ttname"><a href="classTensor.html#a54a0edc085929b2b462574a6a80892b0">Tensor::dims</a></div><div class="ttdeci">const std::vector&lt; unsigned long &gt; &amp; dims() const</div><div class="ttdoc">Gets the tensor dimensions.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8hpp_source.html#l00169">tensor.hpp:169</a></div></div>
<div class="ttc" id="aclassTensor_html_a5660c81a5a0ff70a748f818c07010c87"><div class="ttname"><a href="classTensor.html#a5660c81a5a0ff70a748f818c07010c87">Tensor::at</a></div><div class="ttdeci">float &amp; at(unsigned long i, unsigned long j, unsigned long k, unsigned long l)</div><div class="ttdoc">Accesses tensor element in 4D view (mutable).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8cpp_source.html#l00027">tensor.cpp:27</a></div></div>
<div class="ttc" id="aclassTensor_html_a9a5d2151ffda672db158dd7167a5ae5b"><div class="ttname"><a href="classTensor.html#a9a5d2151ffda672db158dd7167a5ae5b">Tensor::to_matrix</a></div><div class="ttdeci">Matrix to_matrix() const</div><div class="ttdoc">Converts the tensor to a matrix.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8cpp_source.html#l00129">tensor.cpp:129</a></div></div>
<div class="ttc" id="aclassTransformerConfig_html"><div class="ttname"><a href="classTransformerConfig.html">TransformerConfig</a></div><div class="ttdoc">Configuration class for transformer model architecture and training settings.</div><div class="ttdef"><b>Definition</b> <a href="config_8hpp_source.html#l00017">config.hpp:17</a></div></div>
<div class="ttc" id="aclassTransformerConfig_html_a067567832bcaacd2aad3e10862ca0846"><div class="ttname"><a href="classTransformerConfig.html#a067567832bcaacd2aad3e10862ca0846">TransformerConfig::use_sliding_window</a></div><div class="ttdeci">bool use_sliding_window</div><div class="ttdoc">Whether to use sliding window attention.</div><div class="ttdef"><b>Definition</b> <a href="config_8hpp_source.html#l00032">config.hpp:32</a></div></div>
<div class="ttc" id="aclassTransformerConfig_html_a0b988766f47cdbac7f2564d6d464092d"><div class="ttname"><a href="classTransformerConfig.html#a0b988766f47cdbac7f2564d6d464092d">TransformerConfig::max_seq_length</a></div><div class="ttdeci">size_t max_seq_length</div><div class="ttdoc">Maximum sequence length the model can handle.</div><div class="ttdef"><b>Definition</b> <a href="config_8hpp_source.html#l00021">config.hpp:21</a></div></div>
<div class="ttc" id="aclassTransformerConfig_html_a2475d19613be8a719cf766e3bd09e583"><div class="ttname"><a href="classTransformerConfig.html#a2475d19613be8a719cf766e3bd09e583">TransformerConfig::dropout_rate</a></div><div class="ttdeci">float dropout_rate</div><div class="ttdoc">Global dropout rate.</div><div class="ttdef"><b>Definition</b> <a href="config_8hpp_source.html#l00043">config.hpp:43</a></div></div>
<div class="ttc" id="aclassTransformerConfig_html_a5509ab5f50885f2cf531df9d4dd85e0d"><div class="ttname"><a href="classTransformerConfig.html#a5509ab5f50885f2cf531df9d4dd85e0d">TransformerConfig::use_gqa</a></div><div class="ttdeci">bool use_gqa</div><div class="ttdoc">Whether to use grouped-query attention.</div><div class="ttdef"><b>Definition</b> <a href="config_8hpp_source.html#l00034">config.hpp:34</a></div></div>
<div class="ttc" id="aclassTransformerConfig_html_a6991bb420dcaf858cc30dea8211d27fb"><div class="ttname"><a href="classTransformerConfig.html#a6991bb420dcaf858cc30dea8211d27fb">TransformerConfig::use_rope</a></div><div class="ttdeci">bool use_rope</div><div class="ttdoc">Whether to use rotary positional embeddings.</div><div class="ttdef"><b>Definition</b> <a href="config_8hpp_source.html#l00031">config.hpp:31</a></div></div>
<div class="ttc" id="aclassTransformerConfig_html_a9ee7210af942fef7cea9812b509b4f01"><div class="ttname"><a href="classTransformerConfig.html#a9ee7210af942fef7cea9812b509b4f01">TransformerConfig::window_size</a></div><div class="ttdeci">size_t window_size</div><div class="ttdoc">Size of the attention window if using sliding window.</div><div class="ttdef"><b>Definition</b> <a href="config_8hpp_source.html#l00033">config.hpp:33</a></div></div>
<div class="ttc" id="aclassTransformerConfig_html_aeef975a7d6166599e846df0ad66e8a6b"><div class="ttname"><a href="classTransformerConfig.html#aeef975a7d6166599e846df0ad66e8a6b">TransformerConfig::use_flash_attention</a></div><div class="ttdeci">bool use_flash_attention</div><div class="ttdoc">Whether to use flash attention optimization.</div><div class="ttdef"><b>Definition</b> <a href="config_8hpp_source.html#l00030">config.hpp:30</a></div></div>
<div class="ttc" id="aclassTransformerConfig_html_af9260917b6dcbc2ed87690ac8ce6e9fe"><div class="ttname"><a href="classTransformerConfig.html#af9260917b6dcbc2ed87690ac8ce6e9fe">TransformerConfig::use_fp16</a></div><div class="ttdeci">bool use_fp16</div><div class="ttdoc">Whether to use half-precision training.</div><div class="ttdef"><b>Definition</b> <a href="config_8hpp_source.html#l00038">config.hpp:38</a></div></div>
<div class="ttc" id="aclassVector_html"><div class="ttname"><a href="classVector.html">Vector</a></div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00382">matrix.hpp:382</a></div></div>
<div class="ttc" id="aclassVector_html_a5cb80c9602ca8066efa93e31ee230c46"><div class="ttname"><a href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">Vector::size</a></div><div class="ttdeci">size_t size() const</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00402">matrix.hpp:402</a></div></div>
<div class="ttc" id="acomponents_8cpp_html_abd230dec8f3e5ffd751907ff4d2d5993"><div class="ttname"><a href="components_8cpp.html#abd230dec8f3e5ffd751907ff4d2d5993">matmul</a></div><div class="ttdeci">Matrix matmul(const Matrix &amp;a, const Matrix &amp;b)</div><div class="ttdef"><b>Definition</b> <a href="components_8cpp_source.html#l00384">components.cpp:384</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
