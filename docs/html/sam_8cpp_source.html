<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Transformer CPP: src/optimizer/sam.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Transformer CPP
   </div>
   <div id="projectbrief">A C++/CUDA implementation of a Transformer model</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function() { init_codefold(0); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="dir_fef26d3633d38d4ca65fa53115b5e5dd.html">optimizer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle"><div class="title">sam.cpp</div></div>
</div><!--header-->
<div class="contents">
<a href="sam_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="preprocessor">#include &quot;../../include/optimizer/sam.hpp&quot;</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="preprocessor">#include &lt;algorithm&gt;</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="preprocessor">#include &lt;cmath&gt;</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span> </div>
<div class="foldopen" id="foldopen00005" data-start="{" data-end="}">
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno"><a class="line" href="classSAM.html#a45af60c88c640bb58982af77f70c22d2">    5</a></span><span class="keywordtype">float</span> <a class="code hl_function" href="classSAM.html#a45af60c88c640bb58982af77f70c22d2">SAM::compute_grad_norm</a>(<span class="keyword">const</span> std::vector&lt;Matrix&gt;&amp; grads) {</div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span>    <span class="keywordtype">float</span> total_norm = 0.0f;</div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> epsilon = 1e-12f; <span class="comment">// Prevent underflow</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span>    <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; grad : grads) {</div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; grad.size(); ++i) {</div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span>            <span class="comment">// Prevent underflow by clamping tiny gradients</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span>            <span class="keywordtype">float</span> g = grad.data()[i];</div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span>            <span class="keywordflow">if</span> (std::abs(g) &lt; epsilon) {</div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span>                g = 0.0f;</div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span>            }</div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span>            total_norm += g * g;</div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span>        }</div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span>    }</div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span>    <span class="comment">// Prevent sqrt of zero</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span>    total_norm = std::max(total_norm, epsilon * epsilon);</div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span>    <span class="keywordflow">return</span> std::sqrt(total_norm);</div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span>}</div>
</div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span> </div>
<div class="foldopen" id="foldopen00023" data-start="{" data-end="}">
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno"><a class="line" href="classSAM.html#af0ed4370fbe7973c0e0f755b0f3dda60">   23</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classSAM.html#af0ed4370fbe7973c0e0f755b0f3dda60">SAM::save_parameter_copies</a>(<span class="keyword">const</span> std::vector&lt;Matrix*&gt;&amp; params) {</div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span>    <a class="code hl_variable" href="classSAM.html#aa700c63bd917cc6afd1ae4d43714f329">parameter_copies</a>.clear();</div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span>    <a class="code hl_variable" href="classSAM.html#aa700c63bd917cc6afd1ae4d43714f329">parameter_copies</a>.reserve(params.size());</div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span>    <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>* param : params) {</div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span>        <a class="code hl_variable" href="classSAM.html#aa700c63bd917cc6afd1ae4d43714f329">parameter_copies</a>.push_back(*param); <span class="comment">// Make a copy</span></div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span>    }</div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span>}</div>
</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span> </div>
<div class="foldopen" id="foldopen00031" data-start="{" data-end="}">
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno"><a class="line" href="classSAM.html#af79a895a84df2a79fedae5a3ef79215f">   31</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classSAM.html#af79a895a84df2a79fedae5a3ef79215f">SAM::restore_parameters</a>(std::vector&lt;Matrix*&gt;&amp; params) {</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span>    <span class="keywordflow">if</span> (params.size() != <a class="code hl_variable" href="classSAM.html#aa700c63bd917cc6afd1ae4d43714f329">parameter_copies</a>.size()) {</div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span>        <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;Parameter count mismatch during restore&quot;</span>);</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span>    }</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; params.size(); ++i) {</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span>        *params[i] = <a class="code hl_variable" href="classSAM.html#aa700c63bd917cc6afd1ae4d43714f329">parameter_copies</a>[i]; <span class="comment">// Restore the copy</span></div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span>    }</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span>}</div>
</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span> </div>
<div class="foldopen" id="foldopen00040" data-start="{" data-end="}">
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno"><a class="line" href="classSAM.html#ae12cfc89db923baa60205f74592e9f14">   40</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classSAM.html#ae12cfc89db923baa60205f74592e9f14">SAM::first_step</a>(std::vector&lt;Matrix*&gt;&amp; params, <span class="keyword">const</span> std::vector&lt;Matrix&gt;&amp; grads) {</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>    <span class="keywordflow">if</span> (params.size() != grads.size()) {</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span>        <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;Parameter and gradient count mismatch&quot;</span>);</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span>    }</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span> </div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>    <span class="comment">// Save current parameters</span></div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>    <a class="code hl_function" href="classSAM.html#af0ed4370fbe7973c0e0f755b0f3dda60">save_parameter_copies</a>(params);</div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span> </div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>    <span class="comment">// Compute gradient norm</span></div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>    <span class="keywordtype">float</span> grad_norm = <a class="code hl_function" href="classSAM.html#a45af60c88c640bb58982af77f70c22d2">compute_grad_norm</a>(grads);</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> min_norm = 1e-8f;</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>    <span class="keywordflow">if</span> (grad_norm &lt; min_norm) {</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span>        std::cerr &lt;&lt; <span class="stringliteral">&quot;Warning: Very small gradient norm: &quot;</span> &lt;&lt; grad_norm &lt;&lt; std::endl;</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span>        <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>    }</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span> </div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>    <span class="comment">// Scale factor for gradient</span></div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>    <span class="comment">// Clamp scale to prevent extreme values</span></div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>    <span class="keywordtype">float</span> scale = std::min(<a class="code hl_variable" href="classSAM.html#a9252be7fe35a49c20e427a7860173126">rho</a> / grad_norm, 10.0f);</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span> </div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span>    <span class="comment">// Update parameters with scaled gradients</span></div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; params.size(); ++i) {</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>        <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; param = *params[i];</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>        <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; grad = grads[i];</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span> </div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; param.<a class="code hl_function" href="classMatrix.html#aeb6be0338f7e26667962470f4766120b">size</a>(); ++j) {</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>            <span class="comment">// Prevent parameter updates from becoming too large</span></div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>            <span class="keywordtype">float</span> update = scale * grad.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[j];</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>            update = std::clamp(update, -1.0f, 1.0f);</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>            param.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[j] += update;</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>        }</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>    }</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>}</div>
</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span> </div>
<div class="foldopen" id="foldopen00074" data-start="{" data-end="}">
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno"><a class="line" href="classSAM.html#a8ce0dffdaaabcd6d3ecd552c995c868e">   74</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classSAM.html#a8ce0dffdaaabcd6d3ecd552c995c868e">SAM::second_step</a>(std::vector&lt;Matrix*&gt;&amp; params, <span class="keyword">const</span> std::vector&lt;Matrix&gt;&amp; grads) {</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>    <span class="comment">// Restore original parameters</span></div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>    <a class="code hl_function" href="classSAM.html#af79a895a84df2a79fedae5a3ef79215f">restore_parameters</a>(params);</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span> </div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>    <span class="comment">// Apply base optimizer update using step() instead of update()</span></div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>    <a class="code hl_variable" href="classSAM.html#af369b0f3a8ed5421c628ef0a6773753f">base_optimizer</a>-&gt;step(params, grads);</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span>}</div>
</div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span> </div>
<div class="foldopen" id="foldopen00082" data-start="{" data-end="}">
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno"><a class="line" href="classSAM.html#a34e55cbba9fcf52e012378f4a0fe2060">   82</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classSAM.html#a34e55cbba9fcf52e012378f4a0fe2060">SAM::update_bias</a>(std::vector&lt;std::reference_wrapper&lt;FloatVector&gt;&gt;&amp; biases,</div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>                      <span class="keyword">const</span> std::vector&lt;FloatVector&gt;&amp; bias_grads, <span class="keywordtype">float</span> <a class="code hl_variable" href="main_8cpp.html#ad05dcf6fc713294a727588d246d0c924">learning_rate</a>) {</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>    <span class="keywordflow">if</span> (biases.size() != bias_grads.size()) {</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>        <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;Bias and gradient count mismatch&quot;</span>);</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>    }</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span> </div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>    <span class="comment">// Save current biases</span></div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>    <a class="code hl_variable" href="classSAM.html#af3f042f71cf6521327944ba63d3d0370">previous_biases</a>.clear();</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>    <a class="code hl_variable" href="classSAM.html#af3f042f71cf6521327944ba63d3d0370">previous_biases</a>.reserve(biases.size());</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>    <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; bias : biases) {</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>        <a class="code hl_variable" href="classSAM.html#af3f042f71cf6521327944ba63d3d0370">previous_biases</a>.push_back(bias.get());</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>    }</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span> </div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>    <span class="comment">// Update biases</span></div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; biases.size(); ++i) {</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>        <a class="code hl_class" href="classVector.html">FloatVector</a>&amp; bias = biases[i].get();</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>        <span class="keyword">const</span> <a class="code hl_class" href="classVector.html">FloatVector</a>&amp; grad = bias_grads[i];</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span> </div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>        <span class="keywordflow">if</span> (bias.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>() != grad.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>()) {</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>            <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;Bias and gradient size mismatch&quot;</span>);</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>        }</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span> </div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>        <span class="comment">// Apply gradient update</span></div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; bias.<a class="code hl_function" href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">size</a>(); ++j) {</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>            <span class="comment">// Clamp gradients and prevent extreme updates</span></div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>            <span class="keywordtype">float</span> grad_value = std::clamp(grad[j], -10.0f, 10.0f);</div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>            <span class="keywordtype">float</span> update = <a class="code hl_variable" href="main_8cpp.html#ad05dcf6fc713294a727588d246d0c924">learning_rate</a> * grad_value;</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>            update = std::clamp(update, -0.1f, 0.1f);</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>            bias[j] -= update;</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>        }</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>    }</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>}</div>
</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span> </div>
<div class="foldopen" id="foldopen00115" data-start="{" data-end="}">
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno"><a class="line" href="classSAM.html#a947791d4a575675c883cf97d1931c816">  115</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classSAM.html#a947791d4a575675c883cf97d1931c816">SAM::compute_parameter_gradients</a>(<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; logits, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; target_distribution,</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>                                      std::vector&lt;Matrix&gt;&amp; param_grads) {</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>    <span class="comment">// Initialize gradients</span></div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> loss_grad(logits.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(), logits.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>());</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span> </div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>    <span class="comment">// Compute cross entropy gradients with numerical stability</span></div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> epsilon = 1e-12f;</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; logits.<a class="code hl_function" href="classMatrix.html#aeb6be0338f7e26667962470f4766120b">size</a>(); i++) {</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>        <span class="keywordflow">if</span> (target_distribution.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[i] &gt; 0.0f) {</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>            <span class="comment">// Compute stable gradient for cross-entropy loss</span></div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>            <span class="keywordtype">float</span> pred = std::min(std::max(logits.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[i], epsilon), 1.0f - epsilon);</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>            loss_grad.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[i] =</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>                (pred - target_distribution.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[i]) / (pred * (1.0f - pred) + epsilon);</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>        }</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>    }</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span> </div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>    <span class="comment">// Backpropagate through network layers</span></div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> layer = param_grads.size(); layer &gt; 0; --layer) {</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>        <span class="keywordtype">size_t</span> idx = layer - 1;</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span> </div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>        <span class="comment">// Initialize layer gradients if needed</span></div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>        <span class="keywordflow">if</span> (param_grads[idx].empty()) {</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>            param_grads[idx] = <a class="code hl_class" href="classMatrix.html">Matrix</a>(logits.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(), logits.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>());</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>        }</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span> </div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>        <span class="comment">// Compute layer gradients</span></div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; param_grads[idx].size(); i++) {</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>            <span class="keywordtype">float</span> grad = loss_grad.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[i];</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span> </div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>            <span class="comment">// Apply gradient clipping</span></div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>            grad = std::clamp(grad, -10.0f, 10.0f);</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span> </div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>            <span class="comment">// Add small noise for regularization</span></div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>            <span class="keywordtype">float</span> noise = ((float) rand() / RAND_MAX - 0.5f) * 1e-5f;</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>            grad += noise;</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span> </div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span>            param_grads[idx].data()[i] = grad;</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>        }</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span> </div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>        <span class="comment">// Scale gradients for better training stability</span></div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>        <span class="keywordtype">float</span> scale = 1.0f / std::sqrt(<span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(layer + 1));</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; param_grads[idx].size(); i++) {</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>            param_grads[idx].data()[i] *= scale;</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>        }</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>    }</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>}</div>
</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span> </div>
<div class="foldopen" id="foldopen00162" data-start="{" data-end="}">
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno"><a class="line" href="classSAM.html#a516bc474fef96a79047df45c2017a52f">  162</a></span><a class="code hl_class" href="classMatrix.html">Matrix</a> <a class="code hl_function" href="classSAM.html#a516bc474fef96a79047df45c2017a52f">SAM::compute_gradients</a>(<span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; logits, <span class="keyword">const</span> <a class="code hl_class" href="classMatrix.html">Matrix</a>&amp; hidden_states,</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>                              <a class="code hl_class" href="classLanguageModelHead.html">LanguageModelHead</a>* lm_head) {</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>    <span class="comment">// Initialize loss gradient</span></div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> loss_grad(logits.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(), logits.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>());</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span> </div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>    <span class="comment">// Compute initial loss gradients with softmax stability</span></div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> epsilon = 1e-12f;</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; logits.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(); i++) {</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>        <span class="comment">// Find max for numerical stability</span></div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>        <span class="keywordtype">float</span> max_val = logits(i, 0);</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 1; j &lt; logits.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>            max_val = std::max(max_val, logits(i, j));</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>        }</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span> </div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>        <span class="comment">// Compute stable softmax gradients</span></div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>        <span class="keywordtype">float</span> sum_exp = 0.0f;</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>        std::vector&lt;float&gt; exp_vals(logits.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>());</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span> </div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; logits.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>            exp_vals[j] = std::exp(logits(i, j) - max_val);</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>            sum_exp += exp_vals[j];</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>        }</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span> </div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>        <span class="comment">// Compute gradients</span></div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; logits.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>(); j++) {</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>            <span class="keywordtype">float</span> softmax_out = exp_vals[j] / (sum_exp + epsilon);</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>            loss_grad(i, j) =</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>                softmax_out - (j == 0 ? 1.0f : 0.0f); <span class="comment">// Assuming first token is target</span></div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>        }</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>    }</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span> </div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>    <span class="comment">// Backpropagate through language model head</span></div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>    <a class="code hl_class" href="classMatrix.html">Matrix</a> grad = lm_head-&gt;<a class="code hl_function" href="classLanguageModelHead.html#ab424cc22b2908d51b93776915373f198">backward_pass</a>(loss_grad, hidden_states);</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span> </div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>    <span class="comment">// Apply gradient modifications for stability</span></div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; grad.<a class="code hl_function" href="classMatrix.html#aeb6be0338f7e26667962470f4766120b">size</a>(); i++) {</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>        <span class="comment">// Gradient clipping</span></div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>        <span class="keywordtype">float</span> g = std::clamp(grad.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[i], -1.0f, 1.0f);</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span> </div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>        <span class="comment">// Add gradient noise for regularization</span></div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>        <span class="keywordflow">if</span> (grad.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[i] != 0.0f) {</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>            <span class="keywordtype">float</span> noise_scale = 1e-4f * std::abs(grad.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[i]);</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>            <span class="keywordtype">float</span> noise = ((float) rand() / RAND_MAX - 0.5f) * noise_scale;</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>            g += noise;</div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>        }</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span> </div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>        <span class="comment">// Apply gradient scaling</span></div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>        <span class="keywordflow">if</span> (std::abs(g) &lt; epsilon) {</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>            g = 0.0f;</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>        } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>            g *= std::min(1.0f / std::abs(g), 10.0f); <span class="comment">// Scale large gradients</span></div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>        }</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span> </div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>        grad.<a class="code hl_function" href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">data</a>()[i] = g;</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>    }</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span> </div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>    <span class="comment">// Store computed gradients for later use</span></div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classSAM.html#a7548e1290d395c3c8ace25dc4eaa485f">current_gradients</a>.<a class="code hl_function" href="classMatrix.html#a6efb67c1b998ea7ffdc0a1e1b4252e62">empty</a>() || <a class="code hl_variable" href="classSAM.html#a7548e1290d395c3c8ace25dc4eaa485f">current_gradients</a>.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() != grad.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>() ||</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>        <a class="code hl_variable" href="classSAM.html#a7548e1290d395c3c8ace25dc4eaa485f">current_gradients</a>.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>() != grad.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>()) {</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>        <a class="code hl_variable" href="classSAM.html#a7548e1290d395c3c8ace25dc4eaa485f">current_gradients</a> = <a class="code hl_class" href="classMatrix.html">Matrix</a>(grad.<a class="code hl_function" href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">rows</a>(), grad.<a class="code hl_function" href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">cols</a>());</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>    }</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>    <a class="code hl_variable" href="classSAM.html#a7548e1290d395c3c8ace25dc4eaa485f">current_gradients</a> = grad;</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>    <span class="keywordflow">return</span> grad;</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>}</div>
</div>
<div class="ttc" id="aclassLanguageModelHead_html"><div class="ttname"><a href="classLanguageModelHead.html">LanguageModelHead</a></div><div class="ttdoc">Language model head for token prediction in transformer models.</div><div class="ttdef"><b>Definition</b> <a href="lm__head_8hpp_source.html#l00020">lm_head.hpp:20</a></div></div>
<div class="ttc" id="aclassLanguageModelHead_html_ab424cc22b2908d51b93776915373f198"><div class="ttname"><a href="classLanguageModelHead.html#ab424cc22b2908d51b93776915373f198">LanguageModelHead::backward_pass</a></div><div class="ttdeci">Matrix backward_pass(const Matrix &amp;grad_output, const Matrix &amp;hidden_states)</div><div class="ttdoc">Performs the backward pass with Adam optimization.</div><div class="ttdef"><b>Definition</b> <a href="lm__head_8hpp_source.html#l00089">lm_head.hpp:89</a></div></div>
<div class="ttc" id="aclassMatrix_html"><div class="ttname"><a href="classMatrix.html">Matrix</a></div><div class="ttdoc">A 2D matrix class optimized for neural network operations.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00031">matrix.hpp:31</a></div></div>
<div class="ttc" id="aclassMatrix_html_a6efb67c1b998ea7ffdc0a1e1b4252e62"><div class="ttname"><a href="classMatrix.html#a6efb67c1b998ea7ffdc0a1e1b4252e62">Matrix::empty</a></div><div class="ttdeci">bool empty() const</div><div class="ttdoc">Checks if the matrix is empty.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00119">matrix.hpp:119</a></div></div>
<div class="ttc" id="aclassMatrix_html_a8c8b8a4a34ad4a16e6ba28a62010dfa0"><div class="ttname"><a href="classMatrix.html#a8c8b8a4a34ad4a16e6ba28a62010dfa0">Matrix::cols</a></div><div class="ttdeci">size_t cols() const</div><div class="ttdoc">Gets the number of columns.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00087">matrix.hpp:87</a></div></div>
<div class="ttc" id="aclassMatrix_html_a97617f3524bfa47d6ac7daa0eefc1941"><div class="ttname"><a href="classMatrix.html#a97617f3524bfa47d6ac7daa0eefc1941">Matrix::rows</a></div><div class="ttdeci">size_t rows() const</div><div class="ttdoc">Gets the number of rows.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00079">matrix.hpp:79</a></div></div>
<div class="ttc" id="aclassMatrix_html_ab09991ab01bd0b5db9dec6000c36089c"><div class="ttname"><a href="classMatrix.html#ab09991ab01bd0b5db9dec6000c36089c">Matrix::data</a></div><div class="ttdeci">const float * data() const</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00359">matrix.hpp:359</a></div></div>
<div class="ttc" id="aclassMatrix_html_aeb6be0338f7e26667962470f4766120b"><div class="ttname"><a href="classMatrix.html#aeb6be0338f7e26667962470f4766120b">Matrix::size</a></div><div class="ttdeci">size_t size() const</div><div class="ttdoc">Gets the total number of elements.</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00095">matrix.hpp:95</a></div></div>
<div class="ttc" id="aclassSAM_html_a34e55cbba9fcf52e012378f4a0fe2060"><div class="ttname"><a href="classSAM.html#a34e55cbba9fcf52e012378f4a0fe2060">SAM::update_bias</a></div><div class="ttdeci">void update_bias(std::vector&lt; std::reference_wrapper&lt; FloatVector &gt; &gt; &amp;biases, const std::vector&lt; FloatVector &gt; &amp;bias_grads, float learning_rate=0.001f)</div><div class="ttdef"><b>Definition</b> <a href="sam_8cpp_source.html#l00082">sam.cpp:82</a></div></div>
<div class="ttc" id="aclassSAM_html_a45af60c88c640bb58982af77f70c22d2"><div class="ttname"><a href="classSAM.html#a45af60c88c640bb58982af77f70c22d2">SAM::compute_grad_norm</a></div><div class="ttdeci">float compute_grad_norm(const std::vector&lt; Matrix &gt; &amp;grads)</div><div class="ttdef"><b>Definition</b> <a href="sam_8cpp_source.html#l00005">sam.cpp:5</a></div></div>
<div class="ttc" id="aclassSAM_html_a516bc474fef96a79047df45c2017a52f"><div class="ttname"><a href="classSAM.html#a516bc474fef96a79047df45c2017a52f">SAM::compute_gradients</a></div><div class="ttdeci">Matrix compute_gradients(const Matrix &amp;logits, const Matrix &amp;hidden_states, LanguageModelHead *lm_head)</div><div class="ttdef"><b>Definition</b> <a href="sam_8cpp_source.html#l00162">sam.cpp:162</a></div></div>
<div class="ttc" id="aclassSAM_html_a7548e1290d395c3c8ace25dc4eaa485f"><div class="ttname"><a href="classSAM.html#a7548e1290d395c3c8ace25dc4eaa485f">SAM::current_gradients</a></div><div class="ttdeci">Matrix current_gradients</div><div class="ttdef"><b>Definition</b> <a href="sam_8hpp_source.html#l00014">sam.hpp:14</a></div></div>
<div class="ttc" id="aclassSAM_html_a8ce0dffdaaabcd6d3ecd552c995c868e"><div class="ttname"><a href="classSAM.html#a8ce0dffdaaabcd6d3ecd552c995c868e">SAM::second_step</a></div><div class="ttdeci">void second_step(std::vector&lt; Matrix * &gt; &amp;params, const std::vector&lt; Matrix &gt; &amp;grads)</div><div class="ttdef"><b>Definition</b> <a href="sam_8cpp_source.html#l00074">sam.cpp:74</a></div></div>
<div class="ttc" id="aclassSAM_html_a9252be7fe35a49c20e427a7860173126"><div class="ttname"><a href="classSAM.html#a9252be7fe35a49c20e427a7860173126">SAM::rho</a></div><div class="ttdeci">float rho</div><div class="ttdef"><b>Definition</b> <a href="sam_8hpp_source.html#l00009">sam.hpp:9</a></div></div>
<div class="ttc" id="aclassSAM_html_a947791d4a575675c883cf97d1931c816"><div class="ttname"><a href="classSAM.html#a947791d4a575675c883cf97d1931c816">SAM::compute_parameter_gradients</a></div><div class="ttdeci">void compute_parameter_gradients(const Matrix &amp;logits, const Matrix &amp;target_distribution, std::vector&lt; Matrix &gt; &amp;param_grads)</div><div class="ttdef"><b>Definition</b> <a href="sam_8cpp_source.html#l00115">sam.cpp:115</a></div></div>
<div class="ttc" id="aclassSAM_html_aa700c63bd917cc6afd1ae4d43714f329"><div class="ttname"><a href="classSAM.html#aa700c63bd917cc6afd1ae4d43714f329">SAM::parameter_copies</a></div><div class="ttdeci">std::vector&lt; Matrix &gt; parameter_copies</div><div class="ttdef"><b>Definition</b> <a href="sam_8hpp_source.html#l00011">sam.hpp:11</a></div></div>
<div class="ttc" id="aclassSAM_html_ae12cfc89db923baa60205f74592e9f14"><div class="ttname"><a href="classSAM.html#ae12cfc89db923baa60205f74592e9f14">SAM::first_step</a></div><div class="ttdeci">void first_step(std::vector&lt; Matrix * &gt; &amp;params, const std::vector&lt; Matrix &gt; &amp;grads)</div><div class="ttdef"><b>Definition</b> <a href="sam_8cpp_source.html#l00040">sam.cpp:40</a></div></div>
<div class="ttc" id="aclassSAM_html_af0ed4370fbe7973c0e0f755b0f3dda60"><div class="ttname"><a href="classSAM.html#af0ed4370fbe7973c0e0f755b0f3dda60">SAM::save_parameter_copies</a></div><div class="ttdeci">void save_parameter_copies(const std::vector&lt; Matrix * &gt; &amp;params)</div><div class="ttdef"><b>Definition</b> <a href="sam_8cpp_source.html#l00023">sam.cpp:23</a></div></div>
<div class="ttc" id="aclassSAM_html_af369b0f3a8ed5421c628ef0a6773753f"><div class="ttname"><a href="classSAM.html#af369b0f3a8ed5421c628ef0a6773753f">SAM::base_optimizer</a></div><div class="ttdeci">std::unique_ptr&lt; Optimizer &gt; base_optimizer</div><div class="ttdef"><b>Definition</b> <a href="sam_8hpp_source.html#l00010">sam.hpp:10</a></div></div>
<div class="ttc" id="aclassSAM_html_af3f042f71cf6521327944ba63d3d0370"><div class="ttname"><a href="classSAM.html#af3f042f71cf6521327944ba63d3d0370">SAM::previous_biases</a></div><div class="ttdeci">std::vector&lt; FloatVector &gt; previous_biases</div><div class="ttdef"><b>Definition</b> <a href="sam_8hpp_source.html#l00013">sam.hpp:13</a></div></div>
<div class="ttc" id="aclassSAM_html_af79a895a84df2a79fedae5a3ef79215f"><div class="ttname"><a href="classSAM.html#af79a895a84df2a79fedae5a3ef79215f">SAM::restore_parameters</a></div><div class="ttdeci">void restore_parameters(std::vector&lt; Matrix * &gt; &amp;params)</div><div class="ttdef"><b>Definition</b> <a href="sam_8cpp_source.html#l00031">sam.cpp:31</a></div></div>
<div class="ttc" id="aclassVector_html"><div class="ttname"><a href="classVector.html">Vector</a></div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00382">matrix.hpp:382</a></div></div>
<div class="ttc" id="aclassVector_html_a5cb80c9602ca8066efa93e31ee230c46"><div class="ttname"><a href="classVector.html#a5cb80c9602ca8066efa93e31ee230c46">Vector::size</a></div><div class="ttdeci">size_t size() const</div><div class="ttdef"><b>Definition</b> <a href="matrix_8hpp_source.html#l00402">matrix.hpp:402</a></div></div>
<div class="ttc" id="amain_8cpp_html_ad05dcf6fc713294a727588d246d0c924"><div class="ttname"><a href="main_8cpp.html#ad05dcf6fc713294a727588d246d0c924">learning_rate</a></div><div class="ttdeci">float learning_rate</div><div class="ttdef"><b>Definition</b> <a href="main_8cpp_source.html#l00012">main.cpp:12</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
